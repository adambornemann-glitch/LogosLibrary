/-
Author: Adam Bornemann
Created: 11-20-2025
Updated: 11-27-2025

============================================================================================================================
EXPONENTIAL OF SELF-ADJOINT OPERATORS VIA YOSIDA APPROXIMATION
============================================================================================================================

This file constructs the one-parameter unitary group exp(itA) for unbounded
self-adjoint operators A, using the Yosida approximation technique rather
than the spectral theorem.

PHYSICAL MOTIVATION:
  The time evolution operator U(t) = exp(itA) governs quantum dynamics via
  the SchrÃ¶dinger equation. For bounded Hamiltonians, the exponential is
  defined by power series. For unbounded operators (the physical case),
  we need a limiting construction.

HISTORICAL DEVELOPMENT:
  Yosida (1948): Introduced bounded approximants for semigroup generators
  Hille-Yosida (1948): Characterized generators of Câ‚€-semigroups
  Stone (1932): Unitary groups â†” self-adjoint generators (our ultimate goal)

THE YOSIDA STRATEGY:
  For self-adjoint A with resolvent R(z) = (A - zI)â»Â¹:

  1. **Bounded approximants**: Define Aâ‚™ = nÂ²R(in) - inÂ·I
     - Each Aâ‚™ is a bounded operator (unlike A)
     - Aâ‚™ â†’ A strongly on the domain D(A)

  2. **Exponentials exist**: exp(itAâ‚™) is well-defined via power series
     since Aâ‚™ is bounded

  3. **Take the limit**: exp(itA) := s-lim_{nâ†’âˆ} exp(itAâ‚™)
     - Strong operator convergence
     - Limit is unitary because each exp(itAâ‚™) is unitary

WHY NOT USE THE SPECTRAL THEOREM?
  The spectral theorem gives exp(itA) = âˆ« eâ±áµ—áµ¡ dE(Î») directly, but:
  - Constructing the spectral measure E requires significant machinery
  - The Yosida approach is more elementary and generalizes to semigroups
  - Both approaches are valuable; this file takes the constructive route

MATHEMATICAL CONTENT:
  Â§0 Helper lemmas (complex arithmetic for IÂ·n)
  Â§1 Core definitions (resolventAtIn, yosidaApprox, yosidaJ, etc.)
  Â§2 Norm bounds (â€–Aâ‚™â€– â‰¤ 2n, â€–Jâ‚™â€– â‰¤ 1)
  Â§3 Self-adjointness of Aâ‚™Ë¢Ê¸áµ and skew-adjointness of IÂ·Aâ‚™Ë¢Ê¸áµ
  Â§4 J operator identities and convergence (Jâ‚™ â†’ I strongly)
  Â§5 Yosida approximant convergence (Aâ‚™Ï† â†’ AÏ† on domain)
  Â§6 Exponential of bounded operators (definition, group law, adjoint, unitarity)
  Â§7 Unitarity of Yosida exponentials (inner product and norm preservation)
  Â§8 Cauchy sequences and exponential definition (Duhamel estimate, convergence)
  Â§9 Properties of exp(itA) (unitarity, group law, strong continuity, generator = A)

Axiomatized results (marked with sorry):

KEY OPERATORS:
  - R(in) = resolventAtIn: The resolvent at z = in
  - Aâ‚™ = yosidaApprox: Bounded approximant nÂ²R(in) - inÂ·I
  - Aâ‚™Ë¢Ê¸áµ = yosidaApproxSym: Self-adjoint version (nÂ²/2)(R(in) + R(-in))
  - Jâ‚™ = yosidaJ: Auxiliary operator -inÂ·R(in), converges to identity

CONVENTIONS:
  - n ranges over â„•+ (positive naturals) to avoid division by zero
  - I denotes the complex imaginary unit
  - R(z) denotes the resolvent (A - zI)â»Â¹
  - Strong convergence: Tâ‚™ â†’Ë¢ T means Tâ‚™Ï† â†’ TÏ† for all Ï†

Dependencies:
  - Resolvent.lean: resolvent bounds, resolvent identity, range surjectivity

References:
  [1] Yosida, K. "Functional Analysis" (1965) - Chapter IX
  [2] Reed & Simon, "Methods of Modern Mathematical Physics I" - Section VIII.4
  [3] Stone, M.H. "On one-parameter unitary groups" (1932) - Original theorem
-/

import LogosLibrary.DeepTheorems.Quantum.Evolution.Resolvent
import LogosLibrary.DeepTheorems.Quantum.Evolution.Bochner
namespace StonesTheorem.Exponential
open InnerProductSpace MeasureTheory Complex Filter Topology StonesTheorem.Resolvent Generator

open scoped BigOperators Topology
set_option linter.unusedSectionVars false
variable {H : Type*} [NormedAddCommGroup H] [InnerProductSpace â„‚ H] [CompleteSpace H]

/-!
============================================================================================================================
## Section 0: Arithmetic Lemmas for Complex Spectral Parameters
============================================================================================================================

The Yosida approximation evaluates the resolvent at purely imaginary points z = Â±in.
This section establishes the elementary complex arithmetic needed to:
  - Verify Im(in) â‰  0 (so the resolvent exists)
  - Compute |Im(in)| = n (for the resolvent bound)
  - Handle norms of complex scalars

These lemmas are logistically necessary but mathematically trivial.
-/

/-- The imaginary part of IÂ·n is nonzero for positive n.

This is the key hypothesis for resolvent existence: R(z) = (A - zI)â»Â¹ exists
precisely when z is not in the spectrum of A. For self-adjoint A, the spectrum
is real, so any z with Im(z) â‰  0 is in the resolvent set.

For z = IÂ·n with n âˆˆ â„•âº, we have Im(z) = n > 0.
-/
lemma I_mul_pnat_im_ne_zero (n : â„•+) : (I * (n : â„‚)).im â‰  0 := by
  simp only [Complex.mul_im, Complex.I_re, Complex.I_im,
             zero_mul, one_mul, zero_add]
  exact Nat.cast_ne_zero.mpr n.ne_zero

/-- Variant for the conjugate point -IÂ·n.

We need resolvents at both z = in and z = -in for the symmetrized approximant.
-/
lemma neg_I_mul_pnat_im_ne_zero (n : â„•+) : (-I * (n : â„‚)).im â‰  0 := by
  simp only [neg_mul, Complex.neg_im]
  exact neg_ne_zero.mpr (I_mul_pnat_im_ne_zero n)

/-- The imaginary part of IÂ·n equals n.

Direct calculation: Im(IÂ·n) = Im(in) = n.
Used in the resolvent bound â€–R(in)â€– â‰¤ 1/|Im(in)| = 1/n.
-/
lemma I_mul_pnat_im (n : â„•+) : (I * (n : â„‚)).im = (n : â„) := by
  simp [Complex.mul_im]

/-- The absolute value |Im(IÂ·n)| = n.

Since n > 0, the absolute value is just n itself.
-/
lemma abs_I_mul_pnat_im (n : â„•+) : |(I * (n : â„‚)).im| = (n : â„) := by
  rw [I_mul_pnat_im]
  exact abs_of_pos (Nat.cast_pos.mpr n.pos)

/-- Complex norm of nÂ² for n âˆˆ â„•âº.

â€–nÂ²â€–_â„‚ = |nÂ²| = nÂ² since nÂ² is a non-negative real.
Used in bounding â€–nÂ² Â· R(in)â€– = nÂ² Â· â€–R(in)â€–.
-/
lemma norm_pnat_sq (n : â„•+) : â€–((n : â„‚)^2)â€– = (n : â„)^2 := by
  rw [norm_pow]
  simp

/-- Complex norm of IÂ·n equals n.

â€–IÂ·nâ€– = |I| Â· |n| = 1 Â· n = n.
Used throughout the norm bounds on Yosida operators.
-/
lemma norm_I_mul_pnat (n : â„•+) : â€–I * (n : â„‚)â€– = (n : â„) := by
  calc â€–I * (n : â„‚)â€–
      = â€–Iâ€– * â€–(n : â„‚)â€– := norm_mul I (n : â„‚)
    _ = 1 * â€–(n : â„‚)â€– := by rw [Complex.norm_I]
    _ = â€–(n : â„‚)â€– := one_mul _
    _ = (n : â„) := by simp only [Complex.norm_natCast]


/-- The resolvent R(z)Ï† lies in the domain and inverts (A - zI).

For self-adjoint A and z with Im(z) â‰  0:
  - R(z)Ï† âˆˆ D(A) for all Ï† âˆˆ H
  - (A - zI)(R(z)Ï†) = Ï†

This is the defining property of the resolvent as the inverse of (A - zI).
The resolvent maps the full Hilbert space H into the domain D(A), making
it a "regularizing" operator that brings arbitrary vectors into the domain.

**Role in Yosida approximation:**

The bounded approximant Aâ‚™ = nÂ²R(in) - inÂ·I is defined on all of H precisely
because R(in) maps H â†’ D(A). The composition Aâˆ˜R(in) makes sense, giving:

  Aâ‚™Ï† = nÂ²Â·A(R(in)Ï†) - inÂ·Ï† = nÂ²Â·(inÂ·R(in)Ï† + Ï†) - inÂ·Ï†

where we used (A - inÂ·I)R(in) = I, i.e., AÂ·R(in) = inÂ·R(in) + I.
-/
lemma resolvent_spec
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (z : â„‚) (hz : z.im â‰  0) (Ï† : H) :
    (resolvent gen z hz hsa Ï†) âˆˆ gen.domain âˆ§
    gen.op (resolvent gen z hz hsa Ï†) - z â€¢ (resolvent gen z hz hsa Ï†) = Ï† := by
  let Ïˆ_sub := Classical.choose (self_adjoint_range_all_z gen hsa z hz Ï†)
  have h_spec := (Classical.choose_spec (self_adjoint_range_all_z gen hsa z hz Ï†)).1
  exact âŸ¨Ïˆ_sub.property, h_specâŸ©



/-!
============================================================================================================================
## Section 1: The Yosida Operators
============================================================================================================================

We define the key bounded operators that approximate the unbounded generator A:
```markdown

| Operator | Definition | Role |
|----------|------------|------|
| `resolventAtIn n` | R(in) | Resolvent at z = in |
| `resolventAtNegIn n` | R(-in) | Resolvent at conjugate point |
| `yosidaApprox n` | nÂ²R(in) - inÂ·I | Standard Yosida approximant Aâ‚™ |
| `yosidaApproxSym n` | (nÂ²/2)(R(in) + R(-in)) | Self-adjoint approximant |
| `yosidaJ n` | -inÂ·R(in) | Converges to identity |
| `yosidaJNeg n` | inÂ·R(-in) | Conjugate J operator |

```
**Why these specific combinations?**

The resolvent bound â€–R(z)â€– â‰¤ 1/|Im(z)| means â€–R(in)â€– â‰¤ 1/n. Multiplying by nÂ²
gives an O(n) bound, while the combination nÂ²R(in) - inÂ·I is arranged so that:

  Aâ‚™Ï† â†’ AÏ†  for Ï† âˆˆ D(A)

The J operators Jâ‚™ = -inÂ·R(in) satisfy â€–Jâ‚™â€– â‰¤ 1 uniformly and Jâ‚™ â†’ I strongly,
serving as "approximate identities" in the construction.
-/

/-- Resolvent at the point z = IÂ·n.

Bundles R(in) with the proof that Im(in) â‰  0, for convenient use.
-/
noncomputable def resolventAtIn
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) : H â†’L[â„‚] H :=
  resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa

/-- Resolvent at the conjugate point z = -IÂ·n.

Needed for the symmetrized approximant which uses both R(in) and R(-in).
-/
noncomputable def resolventAtNegIn
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) : H â†’L[â„‚] H :=
  resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsa

/-- **The Yosida Approximant**

The standard bounded approximant to the unbounded generator A:

  Aâ‚™ = nÂ² Â· R(in) - in Â· I

**Construction rationale:**

Starting from the resolvent identity (A - inÂ·I)R(in) = I, we get:
  A Â· R(in) = in Â· R(in) + I

Multiplying by nÂ²:
  nÂ² Â· A Â· R(in) = in Â· nÂ² Â· R(in) + nÂ² Â· I

Rearranging for A (heuristically, on the domain):
  A â‰ˆ nÂ² Â· R(in) Â· A = nÂ²(in Â· R(in) + I) Â· (something)

The precise statement is that for Ï† âˆˆ D(A):
  Aâ‚™Ï† = nÂ² Â· R(in) Â· Ï† - in Â· Ï† â†’ AÏ†  as n â†’ âˆ

**Properties:**
  - Bounded: â€–Aâ‚™â€– â‰¤ 2n (grows linearly, but finite for each n)
  - Converges: Aâ‚™Ï† â†’ AÏ† strongly on D(A)
  - Related to J: Aâ‚™ = n Â· (Jâ‚™ - I) where Jâ‚™ = -in Â· R(in)
-/
noncomputable def yosidaApprox
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) : H â†’L[â„‚] H :=
  (n : â„‚)^2 â€¢ resolventAtIn gen hsa n - (I * (n : â„‚)) â€¢ ContinuousLinearMap.id â„‚ H

/-- **Symmetrized Yosida Approximant**

The self-adjoint bounded approximant to the generator A:

  Aâ‚™Ë¢Ê¸áµ = (nÂ²/2) Â· (R(in) + R(-in))

**Why symmetrize?**

The standard approximant Aâ‚™ = nÂ²R(in) - inÂ·I is not self-adjoint because
R(in) alone is not self-adjoint. However, the resolvent satisfies:

  R(z)* = R(zÌ„)

For z = in, we have zÌ„ = -in, so:
  R(in)* = R(-in)

Therefore:
  (R(in) + R(-in))* = R(-in) + R(in) = R(in) + R(-in)

The sum is self-adjoint, making Aâ‚™Ë¢Ê¸áµ self-adjoint.

**Why self-adjointness matters:**

For the exponential exp(itÂ·Aâ‚™Ë¢Ê¸áµ):
  - Self-adjoint Aâ‚™Ë¢Ê¸áµ âŸ¹ iÂ·Aâ‚™Ë¢Ê¸áµ is skew-adjoint
  - Skew-adjoint generator âŸ¹ exp(itÂ·Aâ‚™Ë¢Ê¸áµ) is unitary

This ensures each approximating exponential preserves norms, which passes
to the limit exp(itA).
-/
noncomputable def yosidaApproxSym
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) : H â†’L[â„‚] H :=
  ((n : â„‚)^2 / 2) â€¢ (resolventAtIn gen hsa n + resolventAtNegIn gen hsa n)

/-- **Yosida's J Operator**

The auxiliary operator that converges strongly to the identity:

  Jâ‚™ = -in Â· R(in)

**Key properties:**
  - Uniformly bounded: â€–Jâ‚™â€– â‰¤ 1 for all n
  - Strong convergence: Jâ‚™Ï† â†’ Ï† for all Ï† âˆˆ H
  - Relates to Aâ‚™: The approximant satisfies Aâ‚™ = nÂ·(Jâ‚™ - I) + (terms)

**The name "J":**

In Yosida's original work, Jâ‚™ serves as an "approximate identity" or
"mollifier" â€” it smooths vectors into the domain while converging to
the identity. The uniform bound â€–Jâ‚™â€– â‰¤ 1 is crucial for:
  - Density arguments (controlling â€–Jâ‚™(Ïˆ - Ï†)â€–)
  - Banach-Steinhaus applications
  - Ensuring the limit exists

**Connection to semigroup theory:**

For general Câ‚€-semigroups, Jâ‚™ = nÂ·R(n, A) plays the analogous role,
where R(Î», A) = (Î»I - A)â»Â¹. The self-adjoint case uses imaginary
spectral parameters z = in instead.
-/
noncomputable def yosidaJ
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) : H â†’L[â„‚] H :=
  (-I * (n : â„‚)) â€¢ resolventAtIn gen hsa n

/-- **Conjugate J Operator**

The variant using the negative spectral parameter:

  Jâ‚™â» = in Â· R(-in)

**Relation to Jâ‚™:**

By the resolvent adjoint formula R(z)* = R(zÌ„):
  Jâ‚™* = (-in Â· R(in))* = -(-in) Â· R(in)* = in Â· R(-in) = Jâ‚™â»

So Jâ‚™â» is the adjoint of Jâ‚™. This is used in proving self-adjointness
of the symmetrized approximant.

**Same bound:** â€–Jâ‚™â»â€– â‰¤ 1, by the same argument as for Jâ‚™.
-/
noncomputable def yosidaJNeg
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) : H â†’L[â„‚] H :=
  (I * (n : â„‚)) â€¢ resolventAtNegIn gen hsa n

/-- Resolvent bound at z = in: â€–R(in)â€– â‰¤ 1/n.

This is the fundamental estimate underlying all Yosida bounds.
For self-adjoint A, the resolvent satisfies â€–R(z)â€– â‰¤ 1/|Im(z)|.
At z = in, this gives â€–R(in)â€– â‰¤ 1/n.

**Proof:** Immediate from the general resolvent bound and |Im(in)| = n.
-/
lemma resolventAtIn_bound
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) :
    â€–resolventAtIn gen hsa nâ€– â‰¤ 1 / (n : â„) := by
  unfold resolventAtIn
  calc â€–resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsaâ€–
      â‰¤ 1 / |(I * (n : â„‚)).im| := resolvent_bound gen hsa (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n)
    _ = 1 / (n : â„) := by rw [abs_I_mul_pnat_im]





/-!
============================================================================================================================
## Section 2: Norm Bounds on Yosida Operators
============================================================================================================================

The Yosida operators satisfy crucial norm estimates:
```markdown

| Operator | Bound | Uniformity |
|----------|-------|------------|
| Aâ‚™ = yosidaApprox | â€–Aâ‚™â€– â‰¤ 2n | Grows linearly |
| Jâ‚™ = yosidaJ | â€–Jâ‚™â€– â‰¤ 1 | Uniform |
| Jâ‚™â» = yosidaJNeg | â€–Jâ‚™â»â€– â‰¤ 1 | Uniform |

```
**The significance of these bounds:**

The Aâ‚™ bound â€–Aâ‚™â€– â‰¤ 2n shows each approximant is bounded (unlike A itself),
though the bounds grow. This growth is acceptable because:
  - Each exp(itAâ‚™) is well-defined regardless of â€–Aâ‚™â€–
  - The exponentials are unitary (norm 1) due to self-adjointness
  - Convergence is pointwise, not requiring uniform operator bounds

The Jâ‚™ bound â€–Jâ‚™â€– â‰¤ 1 is uniform and essential for:
  - The density argument showing Jâ‚™ â†’ I strongly
  - Applications of Banach-Steinhaus
  - Controlling error terms in the convergence proof
-/

/-- **Norm Bound on Yosida Approximants**

The bounded Yosida approximants Aâ‚™ = nÂ²R(in) - inÂ·I satisfy:

  â€–Aâ‚™â€– â‰¤ 2n  for all n â‰¥ 1

**Proof outline:**

By the triangle inequality:
  â€–Aâ‚™â€– = â€–nÂ²R(in) - inÂ·Iâ€– â‰¤ â€–nÂ²R(in)â€– + â€–inÂ·Iâ€–

For the first term, using â€–R(in)â€– â‰¤ 1/n:
  â€–nÂ²R(in)â€– = nÂ² Â· â€–R(in)â€– â‰¤ nÂ² Â· (1/n) = n

For the second term:
  â€–inÂ·Iâ€– = |in| Â· â€–Iâ€– = n Â· 1 = n

Total: â€–Aâ‚™â€– â‰¤ n + n = 2n.

**Why linear growth is acceptable:**

The point of Yosida approximation is not to get uniform bounds on Aâ‚™
(impossible â€” they approximate an unbounded operator), but to:
  1. Make each Aâ‚™ bounded, so exp(itAâ‚™) is defined by power series
  2. Have Aâ‚™Ï† â†’ AÏ† on the domain

The exponentials exp(itAâ‚™) have norm 1 (unitary) regardless of â€–Aâ‚™â€–,
because Aâ‚™ inherits self-adjointness properties from A.
-/
theorem yosidaApprox_norm_bound
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) :
    â€–yosidaApprox gen hsa nâ€– â‰¤ 2 * (n : â„) := by
  unfold yosidaApprox

  have h_first : â€–(n : â„‚)^2 â€¢ resolventAtIn gen hsa nâ€– â‰¤ (n : â„) := by
    calc â€–(n : â„‚)^2 â€¢ resolventAtIn gen hsa nâ€–
        = â€–(n : â„‚)^2â€– * â€–resolventAtIn gen hsa nâ€– := norm_smul ((n : â„‚)^2) _
      _ â‰¤ â€–(n : â„‚)^2â€– * (1 / (n : â„)) := by
          apply mul_le_mul_of_nonneg_left (resolventAtIn_bound gen hsa n)
          exact norm_nonneg _
      _ = (n : â„)^2 * (1 / (n : â„)) := by rw [norm_pnat_sq]
      _ = (n : â„) := by field_simp

  have h_second : â€–(I * (n : â„‚)) â€¢ ContinuousLinearMap.id â„‚ Hâ€– â‰¤ (n : â„) := by
    calc â€–(I * (n : â„‚)) â€¢ ContinuousLinearMap.id â„‚ Hâ€–
        = â€–I * (n : â„‚)â€– * â€–ContinuousLinearMap.id â„‚ Hâ€– := norm_smul (I * (n : â„‚)) _
      _ â‰¤ â€–I * (n : â„‚)â€– * 1 := by
          apply mul_le_mul_of_nonneg_left ContinuousLinearMap.norm_id_le
          exact norm_nonneg _
      _ = â€–I * (n : â„‚)â€– := mul_one _
      _ = (n : â„) := norm_I_mul_pnat n

  calc â€–(n : â„‚)^2 â€¢ resolventAtIn gen hsa n - (I * (n : â„‚)) â€¢ ContinuousLinearMap.id â„‚ Hâ€–
      â‰¤ â€–(n : â„‚)^2 â€¢ resolventAtIn gen hsa nâ€– + â€–(I * (n : â„‚)) â€¢ ContinuousLinearMap.id â„‚ Hâ€– :=
          norm_sub_le _ _
    _ â‰¤ (n : â„) + (n : â„) := add_le_add h_first h_second
    _ = 2 * (n : â„) := by ring



/-- **Uniform Bound on Yosida's J Operator**

The auxiliary operators Jâ‚™ = -inÂ·R(in) satisfy the uniform bound:

  â€–Jâ‚™â€– â‰¤ 1  for all n â‰¥ 1

**Proof:**

  â€–Jâ‚™â€– = â€–-inÂ·R(in)â€– = |-in| Â· â€–R(in)â€– = n Â· â€–R(in)â€– â‰¤ n Â· (1/n) = 1

**Why uniformity matters:**

Unlike the Aâ‚™ bound which grows with n, the Jâ‚™ bound is uniform. This is
essential for:

1. **Density argument:** To show Jâ‚™Ïˆ â†’ Ïˆ for all Ïˆ âˆˆ H, we:
   - First prove Jâ‚™Ï† â†’ Ï† for Ï† in the dense domain D(A)
   - Then extend using â€–Jâ‚™(Ïˆ - Ï†)â€– â‰¤ â€–Jâ‚™â€– Â· â€–Ïˆ - Ï†â€– â‰¤ 1 Â· â€–Ïˆ - Ï†â€–

2. **Banach-Steinhaus:** Uniform boundedness of {Jâ‚™} plus pointwise
   convergence on a dense set implies strong convergence everywhere.

3. **Exponential control:** The operators exp(itAâ‚™) can be related to
   powers of Jâ‚™, and uniform bounds on Jâ‚™ help control these.

**The magic of cancellation:**

The factor n from |-in| exactly cancels the 1/n from â€–R(in)â€–, yielding
the clean bound â€–Jâ‚™â€– â‰¤ 1. This is not coincidence â€” it reflects that
Jâ‚™ approximates the identity operator (which has norm 1).
-/
lemma yosidaJ_norm_bound
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) :
    â€–(-I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsaâ€– â‰¤ 1 := by
  have h_neg : (-I : â„‚) * (n : â„‚) = -(I * (n : â„‚)) := by ring

  have h_coeff : â€–(-I * (n : â„‚))â€– = (n : â„) := by
    calc â€–(-I * (n : â„‚))â€–
        = â€–-(I * (n : â„‚))â€– := by rw [h_neg]
      _ = â€–I * (n : â„‚)â€– := norm_neg _
      _ = (n : â„) := norm_I_mul_pnat n

  have h_res : â€–resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsaâ€– â‰¤ 1 / (n : â„) := by
    calc â€–resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsaâ€–
        â‰¤ 1 / |(I * (n : â„‚)).im| := resolvent_bound gen hsa _ _
      _ = 1 / (n : â„) := by rw [abs_I_mul_pnat_im]

  have hn_pos : (0 : â„) < n := Nat.cast_pos.mpr n.pos

  calc â€–(-I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsaâ€–
      = â€–(-I * (n : â„‚))â€– * â€–resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsaâ€– :=
          norm_smul _ _
    _ = (n : â„) * â€–resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsaâ€– := by
          rw [h_coeff]
    _ â‰¤ (n : â„) * (1 / (n : â„)) := by
          apply mul_le_mul_of_nonneg_left h_res
          exact le_of_lt hn_pos
    _ = 1 := by field_simp


/-- **Uniform Bound on the Conjugate J Operator**

The operators Jâ‚™â» = inÂ·R(-in) satisfy the same uniform bound:

  â€–Jâ‚™â»â€– â‰¤ 1  for all n â‰¥ 1

**Proof:**

Identical to the Jâ‚™ bound, using |Im(-in)| = n:
  â€–Jâ‚™â»â€– = |in| Â· â€–R(-in)â€– â‰¤ n Â· (1/n) = 1

**Role:**

Since Jâ‚™â» = Jâ‚™*, uniform boundedness of both operators is needed for
adjoint computations in the self-adjointness proofs.
-/
lemma yosidaJNeg_norm_bound
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) :
    â€–yosidaJNeg gen hsa nâ€– â‰¤ 1 := by
  unfold yosidaJNeg resolventAtNegIn
  have h_coeff : â€–I * (n : â„‚)â€– = (n : â„) := norm_I_mul_pnat n
  have h_res : â€–resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsaâ€– â‰¤ 1 / (n : â„) := by
    calc â€–resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsaâ€–
        â‰¤ 1 / |(-I * (n : â„‚)).im| := resolvent_bound gen hsa _ _
      _ = 1 / (n : â„) := by
          simp only [neg_mul, Complex.neg_im, Complex.mul_im, Complex.I_re,
                     Complex.I_im, zero_mul, one_mul, zero_add]
          rw [â† h_coeff]
          rw [h_coeff]
          rw [@abs_neg]
          rw [natCast_re]
          rw [abs_of_pos (Nat.cast_pos.mpr n.pos)]
  have hn_pos : (0 : â„) < n := Nat.cast_pos.mpr n.pos
  calc â€–(I * (n : â„‚)) â€¢ resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsaâ€–
      = â€–I * (n : â„‚)â€– * â€–resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsaâ€– :=
          norm_smul _ _
    _ = (n : â„) * â€–resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsaâ€– := by
          rw [h_coeff]
    _ â‰¤ (n : â„) * (1 / (n : â„)) := by
          apply mul_le_mul_of_nonneg_left h_res (le_of_lt hn_pos)
    _ = 1 := by field_simp

/-!
============================================================================================================================
## Section 3: Self-Adjointness and Skew-Adjointness
============================================================================================================================

For the exponential exp(itAâ‚™) to be unitary, we need the generator itAâ‚™ to be
skew-adjoint: (itAâ‚™)* = -itAâ‚™. This is equivalent to Aâ‚™ being self-adjoint.

The standard Yosida approximant Aâ‚™ = nÂ²R(in) - inÂ·I is NOT self-adjoint because
R(in) alone is not self-adjoint. However, the resolvent satisfies:

  R(z)* = R(zÌ„)  (adjoint exchanges z with its conjugate)

This motivates the symmetrized approximant:

  Aâ‚™Ë¢Ê¸áµ = (nÂ²/2)(R(in) + R(-in))

Since (in)Ì„ = -in, the sum R(in) + R(-in) is self-adjoint, and multiplying by
the real scalar nÂ²/2 preserves self-adjointness.

**The key chain:**
  Aâ‚™Ë¢Ê¸áµ self-adjoint âŸ¹ iÂ·Aâ‚™Ë¢Ê¸áµ skew-adjoint âŸ¹ exp(itÂ·Aâ‚™Ë¢Ê¸áµ) unitary
-/

/-- **Symmetrized Yosida Approximant is Self-Adjoint**

The operator Aâ‚™Ë¢Ê¸áµ = (nÂ²/2)(R(in) + R(-in)) satisfies:

  (Aâ‚™Ë¢Ê¸áµ)* = Aâ‚™Ë¢Ê¸áµ

**Proof structure:**

The resolvent adjoint formula R(z)* = R(zÌ„) gives:
  - R(in)* = R((in)Ì„) = R(-in)
  - R(-in)* = R((-in)Ì„) = R(in)

Therefore the sum is self-adjoint:
  (R(in) + R(-in))* = R(-in) + R(in) = R(in) + R(-in)

The scalar nÂ²/2 is real (equals its own conjugate), so:
  ((nÂ²/2) Â· T)* = (nÂ²/2)Ì„ Â· T* = (nÂ²/2) Â· T*

Combining: (Aâ‚™Ë¢Ê¸áµ)* = (nÂ²/2)(R(in) + R(-in))* = (nÂ²/2)(R(in) + R(-in)) = Aâ‚™Ë¢Ê¸áµ.

**Why this matters:**

Self-adjointness of Aâ‚™Ë¢Ê¸áµ is the crucial property ensuring that exp(itÂ·Aâ‚™Ë¢Ê¸áµ)
is unitary for all t âˆˆ â„. Without self-adjointness, the exponentials would
not preserve inner products, and the limiting group U(t) = lim exp(itÂ·Aâ‚™Ë¢Ê¸áµ)
would fail to be unitary.

**Technical note:**

The proof works at the level of inner products: âŸ¨TÏ†, ÏˆâŸ© = âŸ¨Ï†, T*ÏˆâŸ©. We show
âŸ¨Aâ‚™Ë¢Ê¸áµ Ï†, ÏˆâŸ© = âŸ¨Ï†, Aâ‚™Ë¢Ê¸áµ ÏˆâŸ© for all Ï†, Ïˆ, which characterizes self-adjointness.
-/
theorem yosidaApproxSym_selfAdjoint
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) :
    (yosidaApproxSym gen hsa n).adjoint = yosidaApproxSym gen hsa n := by
  unfold yosidaApproxSym resolventAtIn resolventAtNegIn
  ext Ï†
  apply ext_inner_right â„‚
  intro Ïˆ

  -- Use âŸ¨T*Ï†, ÏˆâŸ© = âŸ¨Ï†, TÏˆâŸ©
  rw [ContinuousLinearMap.adjoint_inner_left]

  -- Expand the smul and add on both sides
  simp only [ContinuousLinearMap.smul_apply, ContinuousLinearMap.add_apply]

  -- LHS: âŸ¨Ï†, (nÂ²/2) â€¢ (R(in) + R(-in)) ÏˆâŸ©
  -- RHS: âŸ¨(nÂ²/2) â€¢ (R(in) + R(-in)) Ï†, ÏˆâŸ©

  -- The scalar nÂ²/2 is real
  have h_scalar_real : (starRingEnd â„‚) ((n : â„‚)^2 / 2) = (n : â„‚)^2 / 2 := by
    simp only [map_divâ‚€, map_pow]
    congr 1
    simp
    exact conj_eq_iff_re.mpr rfl

  -- Pull scalars through inner products
  rw [inner_smul_right, inner_smul_left, h_scalar_real]
  congr 1

  -- Now show âŸ¨Ï†, (R(in) + R(-in)) ÏˆâŸ© = âŸ¨(R(in) + R(-in)) Ï†, ÏˆâŸ©
  rw [inner_add_right, inner_add_left]

  -- Use resolvent_adjoint: âŸ¨Ï†, R(z)ÏˆâŸ© = âŸ¨R(zÌ„)Ï†, ÏˆâŸ©
  have h1 : âŸªÏ†, resolvent gen (I * â†‘â†‘n) (I_mul_pnat_im_ne_zero n) hsa ÏˆâŸ«_â„‚ =
            âŸªresolvent gen (-I * â†‘â†‘n) (neg_I_mul_pnat_im_ne_zero n) hsa Ï†, ÏˆâŸ«_â„‚ := by
    have hadj := resolvent_adjoint gen hsa (I * â†‘â†‘n) (I_mul_pnat_im_ne_zero n)
    have h_conj : (starRingEnd â„‚) (I * â†‘â†‘n) = -I * â†‘â†‘n := by simp []
    rw [â† ContinuousLinearMap.adjoint_inner_left]
    congr 1
    rw [hadj]
    congr 1
    rw [â† hadj]
    simp_all only [map_divâ‚€, map_pow, map_natCast, neg_mul, map_mul, conj_I]


  have h2 : âŸªÏ†, resolvent gen (-I * â†‘â†‘n) (neg_I_mul_pnat_im_ne_zero n) hsa ÏˆâŸ«_â„‚ =
            âŸªresolvent gen (I * â†‘â†‘n) (I_mul_pnat_im_ne_zero n) hsa Ï†, ÏˆâŸ«_â„‚ := by
    have hadj := resolvent_adjoint gen hsa (-I * â†‘â†‘n) (neg_I_mul_pnat_im_ne_zero n)
    have h_conj : (starRingEnd â„‚) (-I * â†‘â†‘n) = I * â†‘â†‘n := by simp []
    rw [â† ContinuousLinearMap.adjoint_inner_left]
    congr 1
    rw [hadj]
    congr 1
    rw [â† hadj]
    simp_all only [map_divâ‚€, map_pow, map_natCast, neg_mul, map_neg, map_mul, conj_I, neg_neg]

  rw [h1, h2]
  ring


/-- **iÂ·Aâ‚™Ë¢Ê¸áµ is Skew-Adjoint**

For self-adjoint Aâ‚™Ë¢Ê¸áµ, the operator iÂ·Aâ‚™Ë¢Ê¸áµ satisfies:

  (iÂ·Aâ‚™Ë¢Ê¸áµ)* = -iÂ·Aâ‚™Ë¢Ê¸áµ

**Proof:**

Using the adjoint rules (cÂ·T)* = cÌ„Â·T* and the fact that Ä« = -i:

  (iÂ·Aâ‚™Ë¢Ê¸áµ)* = Ä« Â· (Aâ‚™Ë¢Ê¸áµ)*
             = (-i) Â· Aâ‚™Ë¢Ê¸áµ       (by self-adjointness)
             = -(i Â· Aâ‚™Ë¢Ê¸áµ)

**Why skew-adjointness implies unitarity:**

For a bounded operator B, the exponential exp(tB) is unitary for all t âˆˆ â„
if and only if B is skew-adjoint (B* = -B). The proof uses:

  (exp(tB))* = exp(tB*) = exp(-tB) = (exp(tB))â»Â¹

where the last equality is the group property of the exponential.

Applied to B = iÂ·Aâ‚™Ë¢Ê¸áµ, skew-adjointness ensures exp(tÂ·iÂ·Aâ‚™Ë¢Ê¸áµ) is unitary
for all t. Writing t = s for the time parameter:

  U_n(s) := exp(isÂ·Aâ‚™Ë¢Ê¸áµ) is unitary for all s âˆˆ â„

These are the bounded unitary groups that converge to the desired U(s) = exp(isA).

**Connection to Stone's theorem:**

Stone's theorem states that every strongly continuous one-parameter unitary
group U(t) has a unique self-adjoint generator A with U(t) = exp(itA).
The Yosida construction proves the converse: every self-adjoint A generates
such a group. Skew-adjointness of iÂ·Aâ‚™Ë¢Ê¸áµ is the key property making the
approximating groups unitary.
-/
theorem I_smul_yosidaApproxSym_skewAdjoint
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) :
    (I â€¢ yosidaApproxSym gen hsa n).adjoint = -(I â€¢ yosidaApproxSym gen hsa n) := by
  ext Ï†
  apply ext_inner_right â„‚
  intro Ïˆ

  rw [ContinuousLinearMap.adjoint_inner_left]
  simp only [ContinuousLinearMap.smul_apply, ContinuousLinearMap.neg_apply]

  -- LHS: âŸ¨Ï†, i â€¢ Aâ‚™Ë¢Ê¸áµ ÏˆâŸ© = i â€¢ âŸ¨Ï†, Aâ‚™Ë¢Ê¸áµ ÏˆâŸ©
  -- RHS: âŸ¨-(i â€¢ Aâ‚™Ë¢Ê¸áµ Ï†), ÏˆâŸ© = -âŸ¨i â€¢ Aâ‚™Ë¢Ê¸áµ Ï†, ÏˆâŸ© = -Ä« â€¢ âŸ¨Aâ‚™Ë¢Ê¸áµ Ï†, ÏˆâŸ© = i â€¢ âŸ¨Aâ‚™Ë¢Ê¸áµ Ï†, ÏˆâŸ©

  rw [inner_smul_right, inner_neg_left, inner_smul_left]

  -- conj(I) = -I, so -conj(I) = I
  simp only [Complex.conj_I]

  -- Now need: I â€¢ âŸ¨Ï†, Aâ‚™Ë¢Ê¸áµ ÏˆâŸ© = I â€¢ âŸ¨Aâ‚™Ë¢Ê¸áµ Ï†, ÏˆâŸ©
  -- This follows from self-adjointness of Aâ‚™Ë¢Ê¸áµ

  -- âŸ¨Ï†, Aâ‚™Ë¢Ê¸áµ ÏˆâŸ© = âŸ¨(Aâ‚™Ë¢Ê¸áµ)* Ï†, ÏˆâŸ© = âŸ¨Aâ‚™Ë¢Ê¸áµ Ï†, ÏˆâŸ©
  rw [â† ContinuousLinearMap.adjoint_inner_left]
  rw [yosidaApproxSym_selfAdjoint gen hsa n]
  -- âŠ¢ I * âŸª(yosidaApproxSym gen hsa n) Ï†, ÏˆâŸ«_â„‚ = -(-I * âŸª(yosidaApproxSym gen hsa n) Ï†, ÏˆâŸ«_â„‚)
  rw [neg_mul]
  -- âŠ¢ I * âŸª(yosidaApproxSym gen hsa n) Ï†, ÏˆâŸ«_â„‚ = - -(I * âŸª(yosidaApproxSym gen hsa n) Ï†, ÏˆâŸ«_â„‚)
  rw [eq_neg_iff_add_eq_zero, add_eq_zero_iff_neg_eq']
  -- âŠ¢ - -(I * âŸª(yosidaApproxSym gen hsa n) Ï†, ÏˆâŸ«_â„‚) = I * âŸª(yosidaApproxSym gen hsa n) Ï†, ÏˆâŸ«_â„‚
  rw [neg_eq_iff_eq_neg]


/-!
============================================================================================================================
## Section 4: J Operator Identities and Convergence
============================================================================================================================

The auxiliary operators Jâ‚™ = -inÂ·R(in) and Jâ‚™â» = inÂ·R(-in) serve as
"approximate identities" â€” they converge strongly to the identity operator
as n â†’ âˆ. This convergence is the engine driving the Yosida approximation.

**The fundamental identity:**

For Ï† âˆˆ D(A):
  Jâ‚™Ï† = Ï† - R(in)(AÏ†)

This identity reveals why Jâ‚™ â†’ I:
  â€–Jâ‚™Ï† - Ï†â€– = â€–R(in)(AÏ†)â€– â‰¤ â€–R(in)â€–Â·â€–AÏ†â€– â‰¤ (1/n)Â·â€–AÏ†â€– â†’ 0

The convergence rate is O(1/n), controlled by the resolvent bound.

**Extension to all of H:**

The convergence Jâ‚™Ï† â†’ Ï† on the dense domain D(A), combined with the
uniform bound â€–Jâ‚™â€– â‰¤ 1, extends to all Ïˆ âˆˆ H by a standard Îµ/3 argument:
  - Approximate Ïˆ by Ï† âˆˆ D(A)
  - Use Jâ‚™Ï† â†’ Ï†
  - Control the error â€–Jâ‚™(Ïˆ - Ï†)â€– â‰¤ â€–Ïˆ - Ï†â€–

**Role in the construction:**

The convergence Jâ‚™ â†’ I implies:
  - Aâ‚™Ï† = Jâ‚™(AÏ†) + (correction) â†’ AÏ† for Ï† âˆˆ D(A)
  - The approximating groups exp(itAâ‚™) converge to exp(itA)

Both Jâ‚™ and Jâ‚™â» converge to I; having both is useful for adjoint computations
since Jâ‚™â» = Jâ‚™*.
-/

/-- **Fundamental Identity for Yosida's J Operator**

For Ï† in the domain of the self-adjoint generator A:

  Jâ‚™Ï† = Ï† - R(in)(AÏ†)

where Jâ‚™ = -inÂ·R(in) and R(z) = (A - zI)â»Â¹ is the resolvent.

**Derivation:**

Starting from the resolvent equation: for any Ïˆ in the range of (A - zI),
the resolvent satisfies (A - zI)R(z)Ïˆ = Ïˆ.

For Ï† âˆˆ D(A), we can write the "reverse" equation:
  R(z)(A - zI)Ï† = Ï†

Expanding:
  R(z)(AÏ†) - zÂ·R(z)Ï† = Ï†

Rearranging:
  -zÂ·R(z)Ï† = Ï† - R(z)(AÏ†)

With z = in, the left side is (-in)Â·R(in)Ï† = Jâ‚™Ï†.

**Significance:**

This identity is the key to proving Jâ‚™ â†’ I. It shows that the "defect"
Jâ‚™Ï† - Ï† equals -R(in)(AÏ†), which is controlled by:

  â€–Jâ‚™Ï† - Ï†â€– = â€–R(in)(AÏ†)â€– â‰¤ â€–R(in)â€–Â·â€–AÏ†â€– â‰¤ (1/n)Â·â€–AÏ†â€–

For fixed Ï† âˆˆ D(A), the quantity â€–AÏ†â€– is finite, so (1/n)Â·â€–AÏ†â€– â†’ 0.

**Geometric interpretation:**

The identity Jâ‚™ = I - R(in)âˆ˜A says that Jâ‚™ is "almost" the identity,
with a correction term R(in)âˆ˜A that becomes negligible as n â†’ âˆ
(because R(in) shrinks like 1/n while A is fixed on domain elements).
-/
lemma yosidaJ_eq_sub_resolvent_A
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    (-I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa Ï† =
      Ï† - resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†) := by
  -- Let R = R(in) and z = in for clarity
  set z := I * (n : â„‚) with hz_def
  set R := resolvent gen z (I_mul_pnat_im_ne_zero n) hsa with hR_def

  -- R(Ï†) is in domain and satisfies (A - zI)(RÏ†) = Ï†
  have hRÏ†_spec := resolvent_spec gen hsa z (I_mul_pnat_im_ne_zero n) Ï†
  have hRÏ†_domain : R Ï† âˆˆ gen.domain := hRÏ†_spec.1
  have hRÏ†_eq : gen.op (R Ï†) - z â€¢ (R Ï†) = Ï† := hRÏ†_spec.2

  -- From (A - zI)(RÏ†) = Ï†, we get A(RÏ†) = Ï† + zÂ·RÏ†
  have h_ARÏ† : gen.op (R Ï†) = Ï† + z â€¢ (R Ï†) := by
    calc gen.op (R Ï†)
        = (gen.op (R Ï†) - z â€¢ R Ï†) + z â€¢ R Ï† := by abel
      _ = Ï† + z â€¢ R Ï† := by rw [hRÏ†_eq]

  -- R(AÏ†) is in domain and satisfies (A - zI)(R(AÏ†)) = AÏ†
  have hRAÏ†_spec := resolvent_spec gen hsa z (I_mul_pnat_im_ne_zero n) (gen.op Ï†)
  have hRAÏ†_domain : R (gen.op Ï†) âˆˆ gen.domain := hRAÏ†_spec.1
  have hRAÏ†_eq : gen.op (R (gen.op Ï†)) - z â€¢ R (gen.op Ï†) = gen.op Ï† := hRAÏ†_spec.2

  -- Key: R((A-zI)Ï†) = Ï† for Ï† âˆˆ D(A)
  have h_R_AzI : R (gen.op Ï† - z â€¢ Ï†) = Ï† := by
    have h_unique := (Classical.choose_spec
        (self_adjoint_range_all_z gen hsa z (I_mul_pnat_im_ne_zero n) (gen.op Ï† - z â€¢ Ï†))).2
    symm
    have h_subtype : (âŸ¨Ï†, hÏ†âŸ© : {x : H // x âˆˆ gen.domain}) =
        Classical.choose (self_adjoint_range_all_z gen hsa z (I_mul_pnat_im_ne_zero n)
                          (gen.op Ï† - z â€¢ Ï†)) := by
      apply h_unique
      simp only
    calc Ï†
        = (âŸ¨Ï†, hÏ†âŸ© : {x : H // x âˆˆ gen.domain}).val := rfl
      _ = (Classical.choose (self_adjoint_range_all_z gen hsa z (I_mul_pnat_im_ne_zero n)
                              (gen.op Ï† - z â€¢ Ï†))).val := by rw [h_subtype]
      _ = R (gen.op Ï† - z â€¢ Ï†) := rfl

  -- By linearity: R(AÏ† - zÏ†) = R(AÏ†) - zÂ·RÏ†
  have h_R_linear : R (gen.op Ï† - z â€¢ Ï†) = R (gen.op Ï†) - z â€¢ R Ï† := by
    calc R (gen.op Ï† - z â€¢ Ï†)
        = R (gen.op Ï†) - R (z â€¢ Ï†) := by rw [R.map_sub]
      _ = R (gen.op Ï†) - z â€¢ R Ï† := by rw [R.map_smul]

  -- So R(AÏ†) = Ï† + zÂ·RÏ†
  have h_RAÏ†_explicit : R (gen.op Ï†) = Ï† + z â€¢ R Ï† := by
    calc R (gen.op Ï†)
        = R (gen.op Ï†) - z â€¢ R Ï† + z â€¢ R Ï† := by abel
      _ = R (gen.op Ï† - z â€¢ Ï†) + z â€¢ R Ï† := by rw [h_R_linear]
      _ = Ï† + z â€¢ R Ï† := by rw [h_R_AzI]

  -- Conclude: (-z)Â·RÏ† = Ï† - R(AÏ†)
  calc (-I * (n : â„‚)) â€¢ R Ï†
      = (-z) â€¢ R Ï† := by rw [neg_mul]
    _ = -(z â€¢ R Ï†) := by rw [neg_smul]
    _ = Ï† - (Ï† + z â€¢ R Ï†) := by abel
    _ = Ï† - R (gen.op Ï†) := by rw [â† h_RAÏ†_explicit]

/-- **Convergence of J Operator on the Domain**

For Ï† âˆˆ D(A), the sequence Jâ‚™Ï† converges to Ï†:

  Jâ‚™Ï† â†’ Ï†  as n â†’ âˆ

**Proof:**

Using the identity Jâ‚™Ï† = Ï† - R(in)(AÏ†):

  â€–Jâ‚™Ï† - Ï†â€– = â€–R(in)(AÏ†)â€–
            â‰¤ â€–R(in)â€– Â· â€–AÏ†â€–
            â‰¤ (1/n) Â· â€–AÏ†â€–
            â†’ 0

The convergence rate is O(1/n), with constant â€–AÏ†â€–.

**Why domain membership matters:**

For Ï† âˆˆ D(A), the quantity â€–AÏ†â€– is finite, making (1/n)Â·â€–AÏ†â€– a valid
bound that vanishes. For Ï† âˆ‰ D(A), the expression AÏ† is not defined,
and this direct argument fails.

The extension to all of H requires a density argument (see `yosida_J_tendsto_id`).

**Quantitative version:**

Given Îµ > 0, convergence holds for n > â€–AÏ†â€–/Îµ. If AÏ† = 0 (i.e., Ï† is an
eigenvector with eigenvalue 0), then Jâ‚™Ï† = Ï† exactly for all n.
-/
lemma yosidaJ_tendsto_on_domain
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    Tendsto (fun n : â„•+ => (-I * (n : â„‚)) â€¢
              resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa Ï†)
            atTop (ğ“ Ï†) := by
  rw [Metric.tendsto_atTop]
  intro Îµ hÎµ

  by_cases h_AÏ†_zero : â€–gen.op Ï†â€– = 0
  Â· -- Case: AÏ† = 0, so Jâ‚™Ï† = Ï† for all n
    use 1
    intro n _
    rw [yosidaJ_eq_sub_resolvent_A gen hsa n Ï† hÏ†]
    have h_AÏ†_eq_zero : gen.op Ï† = 0 := norm_eq_zero.mp h_AÏ†_zero
    simp only [h_AÏ†_eq_zero, map_zero, sub_zero]
    rw [dist_self]
    exact hÎµ

  Â· -- Case: â€–AÏ†â€– > 0
    have h_AÏ†_pos : 0 < â€–gen.op Ï†â€– := lt_of_le_of_ne (norm_nonneg _) (Ne.symm h_AÏ†_zero)

    -- Choose N > â€–AÏ†â€–/Îµ
    use âŸ¨Nat.ceil (â€–gen.op Ï†â€– / Îµ) + 1, Nat.add_one_pos _âŸ©
    intro n hn

    calc dist ((-I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa Ï†) Ï†
        = â€–(-I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa Ï† - Ï†â€– :=
            dist_eq_norm _ _
      _ = â€–(Ï† - resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†)) - Ï†â€– := by
            rw [yosidaJ_eq_sub_resolvent_A gen hsa n Ï† hÏ†]
      _ = â€–-resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†)â€– := by
            congr 1; abel
      _ = â€–resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†)â€– :=
            norm_neg _
      _ â‰¤ â€–resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsaâ€– * â€–gen.op Ï†â€– :=
            ContinuousLinearMap.le_opNorm _ _
      _ â‰¤ (1 / (n : â„)) * â€–gen.op Ï†â€– := by
            apply mul_le_mul_of_nonneg_right _ (norm_nonneg _)
            calc â€–resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsaâ€–
                â‰¤ 1 / |(I * (n : â„‚)).im| := resolvent_bound gen hsa _ _
              _ = 1 / (n : â„) := by rw [abs_I_mul_pnat_im]
      _ < Îµ := by
            have hn_pos : (0 : â„) < n := Nat.cast_pos.mpr n.pos
            have h_n_bound : â€–gen.op Ï†â€– / Îµ + 1 â‰¤ (n : â„) := by
              have h1 : (Nat.ceil (â€–gen.op Ï†â€– / Îµ) + 1 : â„•) â‰¤ n := hn
              calc â€–gen.op Ï†â€– / Îµ + 1
                  â‰¤ â†‘(Nat.ceil (â€–gen.op Ï†â€– / Îµ)) + 1 :=
                      add_le_add_right (Nat.le_ceil _) _
                _ = â†‘(Nat.ceil (â€–gen.op Ï†â€– / Îµ) + 1) := by norm_cast
                _ â‰¤ (n : â„) := Nat.cast_le.mpr h1
            have h_ratio_lt : â€–gen.op Ï†â€– / Îµ < (n : â„) := by linarith
            have h_prod_lt : â€–gen.op Ï†â€– < (n : â„) * Îµ := by
              calc â€–gen.op Ï†â€–
                  = (â€–gen.op Ï†â€– / Îµ) * Îµ := by field_simp
                _ < (n : â„) * Îµ := mul_lt_mul_of_pos_right h_ratio_lt hÎµ
            calc (1 / (n : â„)) * â€–gen.op Ï†â€–
                = â€–gen.op Ï†â€– / (n : â„) := by ring
              _ = â€–gen.op Ï†â€– * (1 / (n : â„)) := by ring
              _ < ((n : â„) * Îµ) * (1 / (n : â„)) := by
                  apply mul_lt_mul_of_pos_right h_prod_lt
                  exact one_div_pos.mpr hn_pos
              _ = Îµ := by field_simp


/-- **Strong Convergence of J Operator to Identity**

For any Ïˆ âˆˆ H (not necessarily in the domain):

  Jâ‚™Ïˆ â†’ Ïˆ  as n â†’ âˆ

**Proof strategy (Îµ/3 argument):**

Given Ïˆ âˆˆ H and Îµ > 0:

1. **Approximate by domain element:** Since D(A) is dense, choose Ï† âˆˆ D(A)
   with â€–Ïˆ - Ï†â€– < Îµ/3.

2. **Convergence on domain:** By `yosidaJ_tendsto_on_domain`, choose N such
   that n â‰¥ N implies â€–Jâ‚™Ï† - Ï†â€– < Îµ/3.

3. **Combine using uniform bound:** For n â‰¥ N:
```
   â€–Jâ‚™Ïˆ - Ïˆâ€– â‰¤ â€–Jâ‚™Ïˆ - Jâ‚™Ï†â€– + â€–Jâ‚™Ï† - Ï†â€– + â€–Ï† - Ïˆâ€–
             â‰¤ â€–Jâ‚™â€–Â·â€–Ïˆ - Ï†â€– + â€–Jâ‚™Ï† - Ï†â€– + â€–Ï† - Ïˆâ€–
             â‰¤ 1Â·(Îµ/3) + (Îµ/3) + (Îµ/3)
             = Îµ
```

The uniform bound â€–Jâ‚™â€– â‰¤ 1 (from `yosidaJ_norm_bound`) is essential â€” it
allows us to control â€–Jâ‚™(Ïˆ - Ï†)â€– independently of n.

**Why this is the standard pattern:**

This Îµ/3 argument is the canonical way to extend convergence from a dense
set to the whole space when the operators are uniformly bounded. It
appears throughout functional analysis:
  - Extending continuous functions
  - Strong operator convergence
  - Approximation by smooth functions

**Role in Stone's theorem:**

The convergence Jâ‚™ â†’ I (strongly) implies that the Yosida approximants
Aâ‚™ converge to A on the domain:
  Aâ‚™Ï† = Jâ‚™(AÏ†) + O(1/n) â†’ AÏ†

This is the key ingredient for showing exp(itAâ‚™) â†’ exp(itA).
-/
theorem yosida_J_tendsto_id
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (Ïˆ : H) :
    Tendsto (fun n : â„•+ => (-I * (n : â„‚)) â€¢
              resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa Ïˆ)
            atTop (ğ“ Ïˆ) := by
  let J : â„•+ â†’ H â†’L[â„‚] H := fun n =>
    (-I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa

  rw [Metric.tendsto_atTop]
  intro Îµ hÎµ

  -- Step 1: Approximate Ïˆ by domain element Ï†
  have h_dense := gen.dense_domain
  obtain âŸ¨Ï†, hÏ†_mem, hÏ†_closeâŸ© := Metric.mem_closure_iff.mp (h_dense.closure_eq â–¸ Set.mem_univ Ïˆ)
                                    (Îµ / 3) (by linarith)

  -- Step 2: Get N such that Jâ‚™Ï† is close to Ï† for n â‰¥ N
  have h_domain_conv := yosidaJ_tendsto_on_domain gen hsa Ï† hÏ†_mem
  rw [Metric.tendsto_atTop] at h_domain_conv
  obtain âŸ¨N, hNâŸ© := h_domain_conv (Îµ / 3) (by linarith)

  -- Step 3: For n â‰¥ N, Jâ‚™Ïˆ is close to Ïˆ
  use N
  intro n hn

  calc dist (J n Ïˆ) Ïˆ
      â‰¤ dist (J n Ïˆ) (J n Ï†) + dist (J n Ï†) Ï† + dist Ï† Ïˆ := dist_triangle4 _ _ _ _
    _ = â€–J n Ïˆ - J n Ï†â€– + dist (J n Ï†) Ï† + dist Ï† Ïˆ := by rw [dist_eq_norm]
    _ = â€–J n (Ïˆ - Ï†)â€– + dist (J n Ï†) Ï† + dist Ï† Ïˆ := by
        congr 1
        rw [ContinuousLinearMap.map_sub]
    _ â‰¤ â€–J nâ€– * â€–Ïˆ - Ï†â€– + dist (J n Ï†) Ï† + dist Ï† Ïˆ := by
        apply add_le_add_right (add_le_add_right (ContinuousLinearMap.le_opNorm _ _) _)
    _ â‰¤ 1 * â€–Ïˆ - Ï†â€– + dist (J n Ï†) Ï† + dist Ï† Ïˆ := by
        apply add_le_add_right (add_le_add_right _ _)
        apply mul_le_mul_of_nonneg_right (yosidaJ_norm_bound gen hsa n) (norm_nonneg _)
    _ = â€–Ïˆ - Ï†â€– + dist (J n Ï†) Ï† + dist Ï† Ïˆ := by rw [one_mul]
    _ = dist Ïˆ Ï† + dist (J n Ï†) Ï† + dist Ï† Ïˆ := by rw [â† dist_eq_norm]
    _ < Îµ / 3 + Îµ / 3 + Îµ / 3 := by
        have h1 : dist Ïˆ Ï† < Îµ / 3 := hÏ†_close
        have h2 : dist (J n Ï†) Ï† < Îµ / 3 := hN n hn
        have h3 : dist Ï† Ïˆ < Îµ / 3 := by rw [dist_comm]; exact hÏ†_close
        exact add_lt_add (add_lt_add h1 h2) h3
    _ = Îµ := by ring


/-- **Fundamental Identity for Negative J Operator**

For Ï† âˆˆ D(A), the negative J operator satisfies:

  Jâ‚™â»Ï† = Ï† - R(-in)(AÏ†)

This is the exact analogue of `yosidaJ_eq_sub_resolvent_A` for Jâ‚™â» = inÂ·R(-in).

**Derivation:**

From R(-in)(A - (-in)I)Ï† = Ï†, i.e., R(-in)(A + inÂ·I)Ï† = Ï†:
  R(-in)(AÏ†) + inÂ·R(-in)Ï† = Ï†

Rearranging:
  inÂ·R(-in)Ï† = Ï† - R(-in)(AÏ†)

The left side is exactly Jâ‚™â»Ï†.

**Role:**

This identity enables the same convergence proof for Jâ‚™â» as for Jâ‚™:
  â€–Jâ‚™â»Ï† - Ï†â€– = â€–R(-in)(AÏ†)â€– â‰¤ (1/n)Â·â€–AÏ†â€– â†’ 0
-/
lemma yosidaJNeg_eq_sub_resolvent_A
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    (I * (n : â„‚)) â€¢ resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsa Ï† =
      Ï† - resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†) := by
  set z := -I * (n : â„‚) with hz_def
  set R := resolvent gen z (neg_I_mul_pnat_im_ne_zero n) hsa with hR_def

  -- R((A-zI)Ï†) = Ï† for Ï† âˆˆ D(A)
  have h_R_AzI : R (gen.op Ï† - z â€¢ Ï†) = Ï† := by
    have h_unique := (Classical.choose_spec
        (self_adjoint_range_all_z gen hsa z (neg_I_mul_pnat_im_ne_zero n) (gen.op Ï† - z â€¢ Ï†))).2
    symm
    have h_subtype : (âŸ¨Ï†, hÏ†âŸ© : {x : H // x âˆˆ gen.domain}) =
        Classical.choose (self_adjoint_range_all_z gen hsa z (neg_I_mul_pnat_im_ne_zero n)
                          (gen.op Ï† - z â€¢ Ï†)) := by
      apply h_unique
      simp only
    calc Ï†
        = (âŸ¨Ï†, hÏ†âŸ© : {x : H // x âˆˆ gen.domain}).val := rfl
      _ = (Classical.choose (self_adjoint_range_all_z gen hsa z (neg_I_mul_pnat_im_ne_zero n)
                              (gen.op Ï† - z â€¢ Ï†))).val := by rw [h_subtype]
      _ = R (gen.op Ï† - z â€¢ Ï†) := rfl

  -- By linearity: R(AÏ† - zÏ†) = R(AÏ†) - zÂ·RÏ†
  have h_R_linear : R (gen.op Ï† - z â€¢ Ï†) = R (gen.op Ï†) - z â€¢ R Ï† := by
    calc R (gen.op Ï† - z â€¢ Ï†)
        = R (gen.op Ï†) - R (z â€¢ Ï†) := by rw [R.map_sub]
      _ = R (gen.op Ï†) - z â€¢ R Ï† := by rw [R.map_smul]

  -- So R(AÏ†) = Ï† + zÂ·RÏ†
  have h_RAÏ†_explicit : R (gen.op Ï†) = Ï† + z â€¢ R Ï† := by
    calc R (gen.op Ï†)
        = R (gen.op Ï†) - z â€¢ R Ï† + z â€¢ R Ï† := by abel
      _ = R (gen.op Ï† - z â€¢ Ï†) + z â€¢ R Ï† := by rw [h_R_linear]
      _ = Ï† + z â€¢ R Ï† := by rw [h_R_AzI]

  -- Conclude: (in)Â·RÏ† = Ï† - R(AÏ†) since z = -in
  calc (I * (n : â„‚)) â€¢ R Ï†
      = -((-I * (n : â„‚)) â€¢ R Ï†) := by simp only [neg_mul, neg_smul, neg_neg]
    _ = -(z â€¢ R Ï†) := by rw [hz_def]
    _ = Ï† - (Ï† + z â€¢ R Ï†) := by abel
    _ = Ï† - R (gen.op Ï†) := by rw [â† h_RAÏ†_explicit]

/-- **Convergence of Negative J Operator on Domain**

For Ï† âˆˆ D(A): Jâ‚™â»Ï† â†’ Ï† as n â†’ âˆ.

The proof is identical to `yosidaJ_tendsto_on_domain`, using the identity
Jâ‚™â»Ï† = Ï† - R(-in)(AÏ†) and the bound â€–R(-in)â€– â‰¤ 1/n.
-/
lemma yosidaJNeg_tendsto_on_domain
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    Tendsto (fun n : â„•+ => yosidaJNeg gen hsa n Ï†) atTop (ğ“ Ï†) := by
  unfold yosidaJNeg resolventAtNegIn

  have h_identity : âˆ€ n : â„•+,
      (I * (n : â„‚)) â€¢ resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsa Ï† =
      Ï† - resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†) :=
    fun n => yosidaJNeg_eq_sub_resolvent_A gen hsa n Ï† hÏ†

  have h_tendsto : Tendsto (fun n : â„•+ => Ï† - resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†)) atTop (ğ“ Ï†) := by
    -- First show R(-in)(AÏ†) â†’ 0
    have h_to_zero : Tendsto (fun n : â„•+ => resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†)) atTop (ğ“ 0) := by
      apply Metric.tendsto_atTop.mpr
      intro Îµ hÎµ

      obtain âŸ¨N, hNâŸ© := exists_nat_gt (â€–gen.op Ï†â€– / Îµ)
      use âŸ¨N + 1, Nat.succ_pos NâŸ©
      intro n hn

      rw [dist_eq_norm, sub_zero]

      have h_res_bound : â€–resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsaâ€– â‰¤ 1 / (n : â„) := by
        calc â€–resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsaâ€–
            â‰¤ 1 / |(-I * (n : â„‚)).im| := resolvent_bound gen hsa _ _
          _ = 1 / (n : â„) := by
              simp only [neg_mul, Complex.neg_im, Complex.mul_im, Complex.I_re,
                         Complex.I_im, zero_mul, one_mul, zero_add]
              rw [div_eq_div_iff_comm, natCast_re]
              rw [abs_neg, Nat.abs_cast]


      have hn_ge : (n : â„•) â‰¥ N + 1 := hn
      have hn_gt : (n : â„) > N := by
        have h : (N + 1 : â„•) â‰¤ (n : â„•) := hn
        calc (n : â„) â‰¥ (N + 1 : â„•) := Nat.cast_le.mpr h
          _ = N + 1 := by simp
          _ > N := by linarith

      calc â€–resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†)â€–
          â‰¤ â€–resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsaâ€– * â€–gen.op Ï†â€– :=
              ContinuousLinearMap.le_opNorm _ _
        _ â‰¤ (1 / (n : â„)) * â€–gen.op Ï†â€– := by
              apply mul_le_mul_of_nonneg_right h_res_bound (norm_nonneg _)
        _ = â€–gen.op Ï†â€– / (n : â„) := by ring
        _ < Îµ := by
              by_cases hAÏ† : â€–gen.op Ï†â€– = 0
              Â· simp [hAÏ†, hÎµ]
              Â· have hAÏ†_pos : 0 < â€–gen.op Ï†â€– := (norm_nonneg _).lt_of_ne' hAÏ†
                calc â€–gen.op Ï†â€– / (n : â„)
                  < â€–gen.op Ï†â€– / N := by
                      have hN_pos : (0 : â„) < N := by
                        have : 0 < â€–gen.op Ï†â€– / Îµ := div_pos hAÏ†_pos hÎµ
                        linarith
                      apply div_lt_div_of_pos_left hAÏ†_pos hN_pos hn_gt
                _ â‰¤ Îµ := by
                      have hN_pos : (0 : â„) < N := by
                        have : 0 < â€–gen.op Ï†â€– / Îµ := div_pos hAÏ†_pos hÎµ
                        linarith
                      rw [propext (div_le_iffâ‚€ hN_pos)]
                      calc â€–gen.op Ï†â€– = (â€–gen.op Ï†â€– / Îµ) * Îµ := by field_simp
                        _ â‰¤ N * Îµ := by
                            apply mul_le_mul_of_nonneg_right (le_of_lt hN) (le_of_lt hÎµ)
                      linarith

    have h_sub : Tendsto (fun n : â„•+ => Ï† - resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†)) atTop (ğ“ (Ï† - 0)) := by
      exact Filter.Tendsto.sub tendsto_const_nhds h_to_zero
    simp only [sub_zero] at h_sub
    exact h_sub

  exact h_tendsto.congr (fun n => (h_identity n).symm)


/-- **Strong Convergence of Negative J Operator to Identity**

For any Ïˆ âˆˆ H: Jâ‚™â»Ïˆ â†’ Ïˆ as n â†’ âˆ.

**Proof:**

Standard Îµ/3 argument using:
  - D(A) is dense in H
  - â€–Jâ‚™â»â€– â‰¤ 1 uniformly (from `yosidaJNeg_norm_bound`)
  - Jâ‚™â»Ï† â†’ Ï† for Ï† âˆˆ D(A) (from `yosidaJNeg_tendsto_on_domain`)

**Why we need both Jâ‚™ â†’ I and Jâ‚™â» â†’ I:**

Since Jâ‚™â» = Jâ‚™*, having both convergence results is useful for:
  - Adjoint computations in self-adjointness proofs
  - Verifying that the symmetrized operators behave correctly
  - The fact that Jâ‚™â» â†’ I confirms consistency of the construction
-/
lemma yosidaJNeg_tendsto_id
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (h_dense : Dense (gen.domain : Set H))
    (Ïˆ : H) :
    Tendsto (fun n : â„•+ => yosidaJNeg gen hsa n Ïˆ) atTop (ğ“ Ïˆ) := by

  apply Metric.tendsto_atTop.mpr
  intro Îµ hÎµ

  -- Step 1: Approximate Ïˆ by Ï† âˆˆ D(A) with â€–Ïˆ - Ï†â€– < Îµ/3
  have hÎµ3 : Îµ / 3 > 0 := by linarith
  obtain âŸ¨Ï†, hÏ†_mem, hÏ†_closeâŸ© := Metric.mem_closure_iff.mp
    (h_dense.closure_eq â–¸ Set.mem_univ Ïˆ) (Îµ / 3) hÎµ3
  rw [dist_eq_norm] at hÏ†_close

  -- Step 2: For Ï† âˆˆ D(A), Jâ‚™â»Ï† â†’ Ï†
  have h_conv_Ï† := yosidaJNeg_tendsto_on_domain gen hsa Ï† hÏ†_mem
  rw [Metric.tendsto_atTop] at h_conv_Ï†
  obtain âŸ¨N, hNâŸ© := h_conv_Ï† (Îµ / 3) hÎµ3

  use N
  intro n hn
  rw [dist_eq_norm]

  calc â€–yosidaJNeg gen hsa n Ïˆ - Ïˆâ€–
      = â€–(yosidaJNeg gen hsa n Ïˆ - yosidaJNeg gen hsa n Ï†) +
         (yosidaJNeg gen hsa n Ï† - Ï†) + (Ï† - Ïˆ)â€– := by abel_nf
    _ â‰¤ â€–yosidaJNeg gen hsa n Ïˆ - yosidaJNeg gen hsa n Ï†â€– +
        â€–yosidaJNeg gen hsa n Ï† - Ï†â€– + â€–Ï† - Ïˆâ€– := by
          apply le_trans (norm_add_le _ _)
          apply add_le_add_right
          exact norm_add_le _ _
    _ = â€–yosidaJNeg gen hsa n (Ïˆ - Ï†)â€– +
        â€–yosidaJNeg gen hsa n Ï† - Ï†â€– + â€–Ï† - Ïˆâ€– := by
          congr 2
          simp only [map_sub]
    _ â‰¤ â€–yosidaJNeg gen hsa nâ€– * â€–Ïˆ - Ï†â€– +
        â€–yosidaJNeg gen hsa n Ï† - Ï†â€– + â€–Ï† - Ïˆâ€– := by
          apply add_le_add_right
          apply add_le_add_right
          exact ContinuousLinearMap.le_opNorm _ _
    _ â‰¤ 1 * â€–Ïˆ - Ï†â€– + â€–yosidaJNeg gen hsa n Ï† - Ï†â€– + â€–Ï† - Ïˆâ€– := by
          apply add_le_add_right
          apply add_le_add_right
          apply mul_le_mul_of_nonneg_right (yosidaJNeg_norm_bound gen hsa n) (norm_nonneg _)
    _ = â€–Ïˆ - Ï†â€– + â€–yosidaJNeg gen hsa n Ï† - Ï†â€– + â€–Ï† - Ïˆâ€– := by ring
    _ < Îµ / 3 + Îµ / 3 + Îµ / 3 := by
          apply add_lt_add
          apply add_lt_add
          Â· exact hÏ†_close
          Â· rw [â† dist_eq_norm]; exact hN n hn
          Â· rw [norm_sub_rev]; exact hÏ†_close
    _ = Îµ := by ring

/-!
============================================================================================================================
## Section 5: Yosida Approximant Convergence
============================================================================================================================

The bounded Yosida approximants Aâ‚™ converge strongly to the unbounded generator A
on the domain D(A). This is the central approximation result enabling the construction
of exp(itA).

**The key identity:**

For Ï† âˆˆ D(A):
  Aâ‚™Ï† = Jâ‚™(AÏ†)

This factorization through the J operator is the heart of Yosida's method. Since:
  - Jâ‚™ â†’ I strongly (proved in Section 4)
  - AÏ† is a fixed vector in H for Ï† âˆˆ D(A)

we immediately obtain Aâ‚™Ï† = Jâ‚™(AÏ†) â†’ I(AÏ†) = AÏ†.

**The negative and symmetrized approximants:**

We also define:
  - Aâ‚™â» = nÂ²R(-in) + inÂ·I (using the conjugate resolvent)
  - Aâ‚™Ë¢Ê¸áµ = (1/2)(Aâ‚™ + Aâ‚™â») = (nÂ²/2)(R(in) + R(-in))

All three converge to A on the domain, but Aâ‚™Ë¢Ê¸áµ has the crucial property of being
self-adjoint (proved in Section 3), which ensures exp(itÂ·Aâ‚™Ë¢Ê¸áµ) is unitary.

**Commutativity:**

The Yosida approximants commute with all resolvents, a consequence of resolvents
at different spectral points commuting with each other. This ensures the approximating
exponentials exp(itAâ‚™) preserve the domain structure.
-/

/-- **Yosida Approximant as Composition with J**

For Ï† in the domain of a self-adjoint generator A:

  Aâ‚™Ï† = Jâ‚™(AÏ†)

where Aâ‚™ = nÂ²R(in) - inÂ·I is the Yosida approximant and Jâ‚™ = -inÂ·R(in).

**Derivation:**

From the fundamental identity Jâ‚™Ï† = Ï† - R(in)(AÏ†), we can solve for R(in)(AÏ†):
  R(in)(AÏ†) = Ï† - Jâ‚™Ï† = Ï† + inÂ·R(in)Ï†

Now compute Jâ‚™(AÏ†):
  Jâ‚™(AÏ†) = -in Â· R(in)(AÏ†)
         = -in Â· (Ï† + inÂ·R(in)Ï†)
         = -inÂ·Ï† + (-in)(in)Â·R(in)Ï†
         = -inÂ·Ï† + nÂ²Â·R(in)Ï†           [since (-in)(in) = nÂ²]
         = nÂ²Â·R(in)Ï† - inÂ·Ï†
         = Aâ‚™Ï†

**Why this identity is powerful:**

It reduces the convergence Aâ‚™ â†’ A to the already-proved convergence Jâ‚™ â†’ I:
  Aâ‚™Ï† = Jâ‚™(AÏ†) â†’ I(AÏ†) = AÏ†

The composition structure Aâ‚™ = Jâ‚™ âˆ˜ A (on the domain) shows that Aâ‚™ "filters"
the unbounded operator A through the bounded approximate identity Jâ‚™, producing
a bounded approximation.

**Role in the construction:**

This identity is the computational engine of Yosida approximation. Combined with
â€–Jâ‚™â€– â‰¤ 1, it gives quantitative control:
  â€–Aâ‚™Ï† - AÏ†â€– = â€–Jâ‚™(AÏ†) - AÏ†â€– â†’ 0
-/
theorem yosidaApprox_eq_J_comp_A (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    yosidaApprox gen hsa n Ï† = yosidaJ gen hsa n (gen.op Ï†) := by
  -- Get the key identity: Jâ‚™Ï† = Ï† - R(in)(AÏ†)
  have hJ_eq := yosidaJ_eq_sub_resolvent_A gen hsa n Ï† hÏ†
  -- Rearrange to get R(in)(AÏ†) = Ï† + (in) â€¢ R(in)Ï†
  have hR_AÏ† : resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†)
             = Ï† + (I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa Ï† := by
    unfold yosidaJ at hJ_eq
    have h_rearrange : resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†) =
             Ï† - (-I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa Ï† := by
      calc resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†)
          = Ï† - (Ï† - resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†)) := by
              rw [sub_sub_cancel]
        _ = Ï† - (-I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa Ï† := by
              rw [â† hJ_eq]
    calc resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†)
        = Ï† - (-I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa Ï† := h_rearrange
      _ = Ï† + -(-I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa Ï† := by
          rw [sub_eq_add_neg, neg_smul]
      _ = Ï† + (I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa Ï† := by
          congr 2
          ring
  -- Key scalar identity: (-I * n) * (I * n) = nÂ²
  have h_scalar : (-I * (n : â„‚)) * (I * (n : â„‚)) = (n : â„‚)^2 := by
    calc (-I * (n : â„‚)) * (I * (n : â„‚))
        = -I * I * (n : â„‚) * (n : â„‚) := by ring
      _ = -(I * I) * (n : â„‚)^2 := by ring
      _ = -(I^2) * (n : â„‚)^2 := by rw [sq I]
      _ = -(-1) * (n : â„‚)^2 := by rw [Complex.I_sq]
      _ = (n : â„‚)^2 := by ring
  -- Now prove main equality by computing RHS to LHS
  symm
  unfold yosidaApprox yosidaJ
  simp only [resolventAtIn]
  calc (-I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa (gen.op Ï†)
      = (-I * (n : â„‚)) â€¢ (Ï† + (I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) _ hsa Ï†) := by
          rw [hR_AÏ†]
    _ = (-I * (n : â„‚)) â€¢ Ï† + (-I * (n : â„‚)) â€¢ ((I * (n : â„‚)) â€¢ resolvent gen (I * (n : â„‚)) _ hsa Ï†) := by
          rw [smul_add]
    _ = (-I * (n : â„‚)) â€¢ Ï† + ((-I * (n : â„‚)) * (I * (n : â„‚))) â€¢ resolvent gen (I * (n : â„‚)) _ hsa Ï† := by
          rw [smul_smul]
    _ = (-I * (n : â„‚)) â€¢ Ï† + ((n : â„‚)^2) â€¢ resolvent gen (I * (n : â„‚)) _ hsa Ï† := by
          rw [h_scalar]
    _ = ((n : â„‚)^2) â€¢ resolvent gen (I * (n : â„‚)) _ hsa Ï† + (-I * (n : â„‚)) â€¢ Ï† := by
          rw [add_comm]
    _ = ((n : â„‚)^2) â€¢ resolvent gen (I * (n : â„‚)) _ hsa Ï† - (I * (n : â„‚)) â€¢ Ï† := by
          have h_neg : -I * (n : â„‚) = -(I * (n : â„‚)) := by ring
          have h : (-I * (n : â„‚)) â€¢ Ï† = -((I * (n : â„‚)) â€¢ Ï†) := by
            rw [h_neg, neg_smul]
          rw [h, â† sub_eq_add_neg]


/-- **Strong Convergence of Yosida Approximants**

For Ï† âˆˆ D(A), the Yosida approximants converge to the generator:

  Aâ‚™Ï† â†’ AÏ†  as n â†’ âˆ

**Proof:**

This is an immediate corollary of two established results:
  1. Aâ‚™Ï† = Jâ‚™(AÏ†) (from `yosidaApprox_eq_J_comp_A`)
  2. Jâ‚™Ïˆ â†’ Ïˆ for all Ïˆ âˆˆ H (from `yosida_J_tendsto_id`)

Combining: Aâ‚™Ï† = Jâ‚™(AÏ†) â†’ I(AÏ†) = AÏ†.

**Why convergence is only on the domain:**

For Ï† âˆ‰ D(A), the expression AÏ† is undefined, so "Aâ‚™Ï† â†’ AÏ†" is meaningless.
The Yosida approximants Aâ‚™ are bounded operators defined on all of H, but their
limit A is unbounded and only defined on D(A).

**The extension to all of H:**

The unitary group exp(itA) will be defined on all of H, not by extending A,
but by taking the strong limit of the unitary operators exp(itAâ‚™). Since
unitary operators preserve norms, the limit exists and is unitary on all of H.

**Convergence rate:**

From Aâ‚™Ï† = Jâ‚™(AÏ†) and â€–Jâ‚™Ïˆ - Ïˆâ€– â‰¤ (1/n)Â·â€–AÏˆâ€– (for Ïˆ âˆˆ D(A)), we get:
  â€–Aâ‚™Ï† - AÏ†â€– = â€–Jâ‚™(AÏ†) - AÏ†â€– â‰¤ (1/n)Â·â€–A(AÏ†)â€– = (1/n)Â·â€–AÂ²Ï†â€–

for Ï† âˆˆ D(AÂ²). The rate is O(1/n) with constant depending on how "smooth" Ï† is.
-/
theorem yosidaApprox_tendsto_on_domain
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (Ïˆ : H) (hÏˆ : Ïˆ âˆˆ gen.domain) :
    Tendsto (fun n : â„•+ => yosidaApprox gen hsa n Ïˆ) atTop (ğ“ (gen.op Ïˆ)) := by
  -- Aâ‚™Ïˆ = Jâ‚™(AÏˆ) by yosidaApprox_eq_J_comp_A
  -- Jâ‚™(AÏˆ) â†’ AÏˆ by yosida_J_tendsto_id applied to (gen.op Ïˆ)
  simp only [fun n => yosidaApprox_eq_J_comp_A gen hsa n Ïˆ hÏˆ]
  exact yosida_J_tendsto_id gen hsa (gen.op Ïˆ)



/-- **Negative Yosida Approximant**

The "negative" variant using the conjugate resolvent:

  Aâ‚™â» = nÂ²R(-in) + inÂ·I

This is the counterpart to Aâ‚™ = nÂ²R(in) - inÂ·I, obtained by replacing in with -in.

**Relation to the standard approximant:**

The negative approximant satisfies Aâ‚™â» = (Aâ‚™)* when A is self-adjoint, because:
  R(-in) = R((in)Ì„) = R(in)*

**Role:**

The negative approximant is used to form the symmetrized version:
  Aâ‚™Ë¢Ê¸áµ = (1/2)(Aâ‚™ + Aâ‚™â»)

which is self-adjoint and therefore generates unitary exponentials.
-/
noncomputable def yosidaApproxNeg
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) : H â†’L[â„‚] H :=
  ((n : â„‚)^2) â€¢ resolventAtNegIn gen hsa n + (I * (n : â„‚)) â€¢ ContinuousLinearMap.id â„‚ H

/-- **Negative Approximant as Composition with Jâ‚™â»**

For Ï† âˆˆ D(A): Aâ‚™â»Ï† = Jâ‚™â»(AÏ†)

This is the exact analogue of `yosidaApprox_eq_J_comp_A` for the negative variants.

**Derivation:**

From Jâ‚™â»Ï† = Ï† - R(-in)(AÏ†), we get R(-in)(AÏ†) = Ï† - inÂ·R(-in)Ï†.

Computing Jâ‚™â»(AÏ†) = inÂ·R(-in)(AÏ†):
  Jâ‚™â»(AÏ†) = inÂ·(Ï† - inÂ·R(-in)Ï†)
          = inÂ·Ï† - (in)Â²Â·R(-in)Ï†
          = inÂ·Ï† - (-nÂ²)Â·R(-in)Ï†      [since (in)Â² = -nÂ²]
          = inÂ·Ï† + nÂ²Â·R(-in)Ï†
          = Aâ‚™â»Ï†
-/
lemma yosidaApproxNeg_eq_JNeg_A
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    yosidaApproxNeg gen hsa n Ï† = yosidaJNeg gen hsa n (gen.op Ï†) := by
  unfold yosidaApproxNeg yosidaJNeg resolventAtNegIn
  simp only [ContinuousLinearMap.add_apply, ContinuousLinearMap.smul_apply,
             ContinuousLinearMap.id_apply]

  set R := resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsa

  have h := yosidaJNeg_eq_sub_resolvent_A gen hsa n Ï† hÏ†
  have h_RAÏ† : R (gen.op Ï†) = Ï† - (I * (n : â„‚)) â€¢ R Ï† := by
    abel_nf ; rw [h, â† h];
    simp_all only [neg_mul, Int.reduceNeg, neg_smul, one_smul, neg_sub, add_sub_cancel, R]

  -- Compute (in)Â² = -nÂ²
  have h_in_sq : (I * (n : â„‚)) * (I * (n : â„‚)) = -((n : â„‚)^2) := by
    calc (I * (n : â„‚)) * (I * (n : â„‚))
        = I * I * (n : â„‚) * (n : â„‚) := by ring
      _ = (-1) * (n : â„‚) * (n : â„‚) := by rw [I_mul_I]
      _ = -((n : â„‚)^2) := by ring

  symm
  calc (I * (n : â„‚)) â€¢ R (gen.op Ï†)
      = (I * (n : â„‚)) â€¢ (Ï† - (I * (n : â„‚)) â€¢ R Ï†) := by rw [h_RAÏ†]
    _ = (I * (n : â„‚)) â€¢ Ï† - (I * (n : â„‚)) â€¢ ((I * (n : â„‚)) â€¢ R Ï†) := smul_sub _ _ _
    _ = (I * (n : â„‚)) â€¢ Ï† - ((I * (n : â„‚)) * (I * (n : â„‚))) â€¢ R Ï† := by rw [smul_smul]
    _ = (I * (n : â„‚)) â€¢ Ï† - (-((n : â„‚)^2)) â€¢ R Ï† := by rw [h_in_sq]
    _ = (I * (n : â„‚)) â€¢ Ï† + (n : â„‚)^2 â€¢ R Ï† := by rw [neg_smul, sub_neg_eq_add]
    _ = (n : â„‚)^2 â€¢ R Ï† + (I * (n : â„‚)) â€¢ Ï† := by abel



/-- **Negative Approximant Converges on Domain**

For Ï† âˆˆ D(A): Aâ‚™â»Ï† â†’ AÏ† as n â†’ âˆ.

**Proof:**

By the factorization Aâ‚™â»Ï† = Jâ‚™â»(AÏ†) and the convergence Jâ‚™â» â†’ I:
  Aâ‚™â»Ï† = Jâ‚™â»(AÏ†) â†’ I(AÏ†) = AÏ†
-/
lemma yosidaApproxNeg_tendsto_on_domain
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (h_dense : Dense (gen.domain : Set H))
    (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    Tendsto (fun n : â„•+ => yosidaApproxNeg gen hsa n Ï†) atTop (ğ“ (gen.op Ï†)) := by
  have h_eq : âˆ€ n : â„•+, yosidaApproxNeg gen hsa n Ï† = yosidaJNeg gen hsa n (gen.op Ï†) :=
    fun n => yosidaApproxNeg_eq_JNeg_A gen hsa n Ï† hÏ†

  simp_rw [h_eq]
  exact yosidaJNeg_tendsto_id gen hsa h_dense (gen.op Ï†)

/-- **Symmetrized Approximant as Average**

The symmetrized Yosida approximant equals the average of positive and negative:

  Aâ‚™Ë¢Ê¸áµ = (1/2)(Aâ‚™ + Aâ‚™â»)

**Verification:**

  Aâ‚™ + Aâ‚™â» = (nÂ²R(in) - inÂ·I) + (nÂ²R(-in) + inÂ·I)
           = nÂ²R(in) + nÂ²R(-in)
           = nÂ²(R(in) + R(-in))

  (1/2)(Aâ‚™ + Aâ‚™â») = (nÂ²/2)(R(in) + R(-in)) = Aâ‚™Ë¢Ê¸áµ

**Significance:**

This representation shows that Aâ‚™Ë¢Ê¸áµ inherits convergence from both Aâ‚™ and Aâ‚™â».
Since both converge to A on the domain, so does their average.
-/
lemma yosidaApproxSym_eq_avg
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) :
    yosidaApproxSym gen hsa n = (1/2 : â„‚) â€¢ (yosidaApprox gen hsa n + yosidaApproxNeg gen hsa n) := by
  unfold yosidaApproxSym yosidaApprox yosidaApproxNeg resolventAtIn resolventAtNegIn
  ext Ïˆ
  simp only [ContinuousLinearMap.smul_apply, ContinuousLinearMap.add_apply,
             ContinuousLinearMap.sub_apply, ContinuousLinearMap.id_apply]
  set R_pos := resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa
  set R_neg := resolvent gen (-I * (n : â„‚)) (neg_I_mul_pnat_im_ne_zero n) hsa

  have h : (1 / 2 : â„‚) * (n : â„‚)^2 = (n : â„‚)^2 / 2 := by ring

  calc ((n : â„‚)^2 / 2) â€¢ (R_pos Ïˆ + R_neg Ïˆ)
      = ((n : â„‚)^2 / 2) â€¢ R_pos Ïˆ + ((n : â„‚)^2 / 2) â€¢ R_neg Ïˆ := smul_add _ _ _
    _ = (1 / 2 : â„‚) â€¢ ((n : â„‚)^2 â€¢ R_pos Ïˆ) + (1 / 2 : â„‚) â€¢ ((n : â„‚)^2 â€¢ R_neg Ïˆ) := by
        simp only [smul_smul]; ring_nf
    _ = (1 / 2 : â„‚) â€¢ ((n : â„‚)^2 â€¢ R_pos Ïˆ + (n : â„‚)^2 â€¢ R_neg Ïˆ) := by rw [â† smul_add]
    _ = (1 / 2 : â„‚) â€¢ ((n : â„‚)^2 â€¢ R_pos Ïˆ - (I * (n : â„‚)) â€¢ Ïˆ + ((n : â„‚)^2 â€¢ R_neg Ïˆ + (I * (n : â„‚)) â€¢ Ïˆ)) := by
        congr 1; abel
    _ = (1 / 2 : â„‚) â€¢ (((n : â„‚)^2 â€¢ R_pos Ïˆ - (I * (n : â„‚)) â€¢ Ïˆ) + ((n : â„‚)^2 â€¢ R_neg Ïˆ + (I * (n : â„‚)) â€¢ Ïˆ)) := by
        congr 1;

/-- **Symmetrized Approximant Converges on Domain**

For Ï† âˆˆ D(A): Aâ‚™Ë¢Ê¸áµÏ† â†’ AÏ† as n â†’ âˆ.

**Proof:**

Since Aâ‚™Ë¢Ê¸áµ = (1/2)(Aâ‚™ + Aâ‚™â») and both Aâ‚™Ï† â†’ AÏ† and Aâ‚™â»Ï† â†’ AÏ†:
  Aâ‚™Ë¢Ê¸áµÏ† = (1/2)(Aâ‚™Ï† + Aâ‚™â»Ï†) â†’ (1/2)(AÏ† + AÏ†) = AÏ†

**Role in Stone's theorem:**

This is the convergence result we actually use: the symmetrized approximants
converge to A on the domain. Combined with self-adjointness of Aâ‚™Ë¢Ê¸áµ (which
ensures exp(itÂ·Aâ‚™Ë¢Ê¸áµ) is unitary), this gives the complete Yosida construction.
-/
theorem yosidaApproxSym_tendsto_on_domain
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (h_dense : Dense (gen.domain : Set H))
    (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    Tendsto (fun n : â„•+ => yosidaApproxSym gen hsa n Ï†) atTop (ğ“ (gen.op Ï†)) := by
  have h_eq : âˆ€ n : â„•+, yosidaApproxSym gen hsa n Ï† =
      (1/2 : â„‚) â€¢ (yosidaApprox gen hsa n Ï† + yosidaApproxNeg gen hsa n Ï†) := by
    intro n
    calc yosidaApproxSym gen hsa n Ï†
        = ((1/2 : â„‚) â€¢ (yosidaApprox gen hsa n + yosidaApproxNeg gen hsa n)) Ï† := by
            rw [yosidaApproxSym_eq_avg]
      _ = (1/2 : â„‚) â€¢ (yosidaApprox gen hsa n Ï† + yosidaApproxNeg gen hsa n Ï†) := by
            simp only [ContinuousLinearMap.smul_apply, ContinuousLinearMap.add_apply]

  simp_rw [h_eq]

  have h_pos := yosidaApprox_tendsto_on_domain gen hsa Ï† hÏ†
  have h_neg := yosidaApproxNeg_tendsto_on_domain gen hsa h_dense Ï† hÏ†

  have h_sum : Tendsto (fun n : â„•+ => yosidaApprox gen hsa n Ï† + yosidaApproxNeg gen hsa n Ï†)
      atTop (ğ“ (gen.op Ï† + gen.op Ï†)) := h_pos.add h_neg

  have h_half : Tendsto (fun n : â„•+ => (1/2 : â„‚) â€¢ (yosidaApprox gen hsa n Ï† + yosidaApproxNeg gen hsa n Ï†))
      atTop (ğ“ ((1/2 : â„‚) â€¢ (gen.op Ï† + gen.op Ï†))) := h_sum.const_smul (1/2 : â„‚)

  have h_simp : (1/2 : â„‚) â€¢ (gen.op Ï† + gen.op Ï†) = gen.op Ï† := by
    rw [â† two_smul â„‚ (gen.op Ï†), smul_smul]
    norm_num

  rw [h_simp] at h_half
  exact h_half


/-- **Yosida Approximants Commute with Resolvents**

The bounded Yosida approximants commute with the resolvent at any spectral point:

  Aâ‚™ âˆ˜ R(z) = R(z) âˆ˜ Aâ‚™  for all z with Im(z) â‰  0

**Proof:**

Since Aâ‚™ = nÂ²R(in) - inÂ·I, commutativity reduces to showing resolvents commute:
  R(in) âˆ˜ R(z) = R(z) âˆ˜ R(in)

From the resolvent identity R(wâ‚) - R(wâ‚‚) = (wâ‚ - wâ‚‚)Â·R(wâ‚)âˆ˜R(wâ‚‚), both orderings
give the same expression (wâ‚ - wâ‚‚)â»Â¹Â·(R(wâ‚) - R(wâ‚‚)), establishing commutativity.

**Significance:**

Commutativity Aâ‚™ âˆ˜ R(z) = R(z) âˆ˜ Aâ‚™ extends to the exponentials:
  exp(itAâ‚™) âˆ˜ R(z) = R(z) âˆ˜ exp(itAâ‚™)

This ensures:
  1. exp(itAâ‚™) preserves the domain D(A) = Range(R(z))
  2. The limiting group exp(itA) has the correct domain properties
  3. The generator of the limit group is indeed A
-/
theorem yosidaApprox_commutes_resolvent
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) (z : â„‚) (hz : z.im â‰  0) :
    (yosidaApprox gen hsa n).comp (resolvent gen z hz hsa)
      = (resolvent gen z hz hsa).comp (yosidaApprox gen hsa n) := by
  -- First establish that resolvents commute
  have h_resolvent_comm : (resolventAtIn gen hsa n).comp (resolvent gen z hz hsa) =
                          (resolvent gen z hz hsa).comp (resolventAtIn gen hsa n) := by
    unfold resolventAtIn
    by_cases h_eq : I * (n : â„‚) = z
    Â· have hz' : (I * (n : â„‚)).im â‰  0 := I_mul_pnat_im_ne_zero n
      have h_res_eq : resolvent gen (I * (n : â„‚)) hz' hsa = resolvent gen z hz hsa := by
        subst h_eq
        congr
      rw [h_res_eq]
    Â· have h_diff_ne : I * (n : â„‚) - z â‰  0 := sub_ne_zero.mpr h_eq
      have h_diff_ne' : z - I * (n : â„‚) â‰  0 := sub_ne_zero.mpr (Ne.symm h_eq)
      have h_id1 := resolvent_identity gen hsa (I * (n : â„‚)) z (I_mul_pnat_im_ne_zero n) hz
      have h_id2 := resolvent_identity gen hsa z (I * (n : â„‚)) hz (I_mul_pnat_im_ne_zero n)
      have h1 : (resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa).comp (resolvent gen z hz hsa) =
                (I * (n : â„‚) - z)â»Â¹ â€¢ (resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa - resolvent gen z hz hsa) := by
        symm
        calc (I * (n : â„‚) - z)â»Â¹ â€¢ (resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa - resolvent gen z hz hsa)
            = (I * (n : â„‚) - z)â»Â¹ â€¢ ((I * (n : â„‚) - z) â€¢ (resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa).comp (resolvent gen z hz hsa)) := by
                rw [h_id1]
          _ = (resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa).comp (resolvent gen z hz hsa) := by
                rw [smul_smul, inv_mul_cancelâ‚€ h_diff_ne, one_smul]
      have h2 : (resolvent gen z hz hsa).comp (resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa) =
                (z - I * (n : â„‚))â»Â¹ â€¢ (resolvent gen z hz hsa - resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa) := by
        symm
        calc (z - I * (n : â„‚))â»Â¹ â€¢ (resolvent gen z hz hsa - resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa)
            = (z - I * (n : â„‚))â»Â¹ â€¢ ((z - I * (n : â„‚)) â€¢ (resolvent gen z hz hsa).comp (resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa)) := by
                rw [h_id2]
          _ = (resolvent gen z hz hsa).comp (resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa) := by
                rw [smul_smul, inv_mul_cancelâ‚€ h_diff_ne', one_smul]
      rw [h1, h2]
      have h_inv_neg : (z - I * (n : â„‚))â»Â¹ = -(I * (n : â„‚) - z)â»Â¹ := by
        rw [â† neg_sub, neg_inv]
      have h_sub_neg : resolvent gen z hz hsa - resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa =
                      -(resolvent gen (I * (n : â„‚)) (I_mul_pnat_im_ne_zero n) hsa - resolvent gen z hz hsa) := by
        rw [neg_sub]
      rw [h_inv_neg, h_sub_neg, smul_neg, neg_smul, neg_neg]
  -- Now expand yosidaApprox and use resolvent commutativity
  unfold yosidaApprox
  rw [ContinuousLinearMap.sub_comp, ContinuousLinearMap.comp_sub]
  rw [ContinuousLinearMap.smul_comp, ContinuousLinearMap.comp_smul]
  rw [ContinuousLinearMap.smul_comp, ContinuousLinearMap.comp_smul]
  rw [ContinuousLinearMap.id_comp, ContinuousLinearMap.comp_id]
  congr 1
  unfold resolventAtIn
  simp only [resolventAtIn] at h_resolvent_comm
  rw [h_resolvent_comm]

/-!
============================================================================================================================
## Section 6: Exponential of Bounded Operators
============================================================================================================================

With the Yosida approximants Aâ‚™ established as bounded operators converging to A
on the domain, we now define and study the exponential exp(tB) for bounded B.

**Definition:**

For bounded B : H â†’L[â„‚] H and t âˆˆ â„:

  exp(tB) = Î£â‚–â‚Œâ‚€^âˆ (tB)áµ / k!

The series converges absolutely in operator norm since â€–(tB)áµ/k!â€– â‰¤ (|t|Â·â€–Bâ€–)áµ/k!
and Î£ xáµ/k! = eË£ converges for all x.

**Key properties:**

1. **Semigroup law:** exp((s+t)B) = exp(sB) Â· exp(tB)
2. **Norm bound:** â€–exp(tB)â€– â‰¤ exp(|t|Â·â€–Bâ€–)
3. **Adjoint:** exp(tB)* = exp(tB*)
4. **Unitarity:** If B* = -B (skew-adjoint), then exp(tB) is unitary

**Application to Yosida:**

The approximants iÂ·Aâ‚™Ë¢Ê¸áµ are skew-adjoint (since Aâ‚™Ë¢Ê¸áµ is self-adjoint), so
exp(tÂ·iÂ·Aâ‚™Ë¢Ê¸áµ) is unitary for all t. These unitary operators form the approximating
sequence whose strong limit defines exp(itA).
-/

/-- **Exponential of a Bounded Operator**

For bounded B : H â†’L[â„‚] H and t âˆˆ â„, the operator exponential:

  exp(tB) = Î£â‚–â‚Œâ‚€^âˆ (tB)áµ / k!

**Convergence:**

The series converges absolutely in operator norm. For each term:
  â€–(tB)áµ / k!â€– â‰¤ (|t| Â· â€–Bâ€–)áµ / k!

The sum Î£â‚– (|t|Â·â€–Bâ€–)áµ/k! = exp(|t|Â·â€–Bâ€–) < âˆ, so the series converges by comparison.

**Properties:**

  - exp(0Â·B) = I (identity at t = 0)
  - exp((s+t)B) = exp(sB) Â· exp(tB) (semigroup law)
  - d/dt exp(tB) = B Â· exp(tB) (generator property)
  - If B* = -B, then exp(tB) is unitary

**Role in Stone's theorem:**

The Yosida approximants Aâ‚™ are bounded, so exp(itAâ‚™) is well-defined by this
power series. The unitary group exp(itA) for unbounded self-adjoint A is the
strong limit of these bounded exponentials.

**Implementation note:**

We use Mathlib's `NormedSpace.exp` for the Banach algebra H â†’L[â„‚] H, which provides
the same power series definition along with algebraic properties.
-/
noncomputable def expBounded (B : H â†’L[â„‚] H) (t : â„) : H â†’L[â„‚] H :=
  âˆ‘' (k : â„•), (1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B) ^ k


/-- **Semigroup Law for Bounded Exponentials**

The exponential satisfies the fundamental semigroup property:

  exp((s + t)B) = exp(sB) âˆ˜ exp(tB)

**Proof:**

Since sB and tB commute (both are scalar multiples of B), the Cauchy product
formula for absolutely convergent series gives:

  exp(sB) Â· exp(tB) = (Î£â±¼ (sB)Ê²/j!) Â· (Î£â‚– (tB)áµ/k!)
                    = Î£â‚™ Î£â±¼â‚Šâ‚–â‚Œâ‚™ (sB)Ê²(tB)áµ / (j!k!)
                    = Î£â‚™ (Bâ¿/n!) Â· Î£â±¼â‚Œâ‚€â¿ C(n,j) sÊ² tâ¿â»Ê²
                    = Î£â‚™ ((s+t)B)â¿ / n!        [binomial theorem]
                    = exp((s+t)B)

**Commutativity is essential:**

The identity exp(X)exp(Y) = exp(X+Y) holds only when X and Y commute. For
non-commuting operators, the Baker-Campbell-Hausdorff formula applies instead.

**Role in Stone's theorem:**

This law ensures t â†¦ exp(itAâ‚™) is a one-parameter group for each n. The group
law passes to the strong limit, establishing t â†¦ exp(itA) as a group.
-/
theorem expBounded_group_law (B : H â†’L[â„‚] H) (s t : â„) :
    expBounded B (s + t) = (expBounded B s).comp (expBounded B t) := by
  unfold expBounded

  have h_eq_exp : âˆ€ c : â„‚, (âˆ‘' k : â„•, (1 / k.factorial : â„‚) â€¢ (c â€¢ B) ^ k) =
      NormedSpace.exp â„‚ (c â€¢ B) := by
    intro c
    rw [NormedSpace.exp_eq_tsum]
    congr 1
    ext k
    rw [one_div]

  have h_comm : Commute ((s : â„‚) â€¢ B) ((t : â„‚) â€¢ B) := by
    show ((s : â„‚) â€¢ B) * ((t : â„‚) â€¢ B) = ((t : â„‚) â€¢ B) * ((s : â„‚) â€¢ B)
    rw [smul_mul_smul, smul_mul_smul, mul_comm (s : â„‚) (t : â„‚)]

  simp only [h_eq_exp]
  simp only [Complex.ofReal_add, add_smul]
  rw [NormedSpace.exp_add_of_commute h_comm]
  rfl


/-- **Norm Bound for Bounded Exponentials**

The exponential satisfies the standard estimate:

  â€–exp(tB)â€– â‰¤ exp(|t| Â· â€–Bâ€–)

**Proof:**

  â€–exp(tB)â€– = â€–Î£â‚– (tB)áµ/k!â€–
            â‰¤ Î£â‚– â€–(tB)áµ/k!â€–
            â‰¤ Î£â‚– â€–tBâ€–áµ/k!
            = exp(â€–tBâ€–)
            = exp(|t| Â· â€–Bâ€–)

**Significance:**

This bound shows â€–exp(tB)â€– grows at most exponentially in |t|. For skew-adjoint B,
the actual norm is 1 (unitary), but this general bound applies to all bounded B.

**For Yosida approximants:**

Applied to B = iÂ·Aâ‚™Ë¢Ê¸áµ, this gives â€–exp(itÂ·Aâ‚™Ë¢Ê¸áµ)â€– â‰¤ exp(|t|Â·â€–Aâ‚™Ë¢Ê¸áµâ€–). However,
since iÂ·Aâ‚™Ë¢Ê¸áµ is skew-adjoint, the sharp bound is â€–exp(itÂ·Aâ‚™Ë¢Ê¸áµ)â€– = 1.
-/
theorem expBounded_norm_bound (B : H â†’L[â„‚] H) (t : â„) :
    â€–expBounded B tâ€– â‰¤ Real.exp (|t| * â€–Bâ€–) := by
  unfold expBounded
  set X := (t : â„‚) â€¢ B with hX
  set f := (fun n : â„• => (n.factorial : â„‚)â»Â¹ â€¢ X ^ n) with hf
  set g := (fun n : â„• => â€–Xâ€– ^ n / n.factorial) with hg

  have h_norm_summable : Summable g := Real.summable_pow_div_factorial â€–Xâ€–

  have h_term_le : âˆ€ n, â€–f nâ€– â‰¤ g n := fun n => by
    simp only [hf, hg]
    rw [norm_smul, norm_inv, Complex.norm_natCast, div_eq_inv_mul]
    gcongr
    exact opNorm_pow_le X n

  have h_summable : Summable f :=
    Summable.of_norm_bounded (g := g) h_norm_summable h_term_le

  have h_eq_exp : (âˆ‘' k : â„•, (1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B) ^ k) =
      âˆ‘' n, f n := by
    congr 1; ext k
    simp only [hf, one_div]
    abel
  have h_exp_eq : NormedSpace.exp â„‚ X = âˆ‘' n, f n := by
    rw [NormedSpace.exp_eq_tsum]

  have h_norm_f_summable : Summable (fun n => â€–f nâ€–) :=
    Summable.of_nonneg_of_le (fun n => norm_nonneg _) h_term_le h_norm_summable

  have h1 : â€–âˆ‘' n, f nâ€– â‰¤ âˆ‘' n, â€–f nâ€– := by
    apply norm_tsum_le_tsum_norm
    exact h_norm_f_summable

  have h2 : âˆ‘' n, â€–f nâ€– â‰¤ âˆ‘' n, g n := by
    apply Summable.tsum_le_tsum h_term_le h_norm_f_summable h_norm_summable

  have h3 : âˆ‘' n, g n = Real.exp â€–Xâ€– := by
    simp only [hg]
    rw [Real.exp_eq_exp_â„, NormedSpace.exp_eq_tsum_div]

  have h4 : â€–Xâ€– = |t| * â€–Bâ€– := by
    simp only [hX]
    rw [norm_smul, Complex.norm_real, Real.norm_eq_abs]

  rw [h_eq_exp]
  calc â€–âˆ‘' n, f nâ€–
      â‰¤ âˆ‘' n, â€–f nâ€– := h1
    _ â‰¤ âˆ‘' n, g n := h2
    _ = Real.exp â€–Xâ€– := h3
    _ = Real.exp (|t| * â€–Bâ€–) := by rw [h4]

/-- Specialized bound for Yosida approximant exponential. -/
theorem expBounded_yosida_norm_le
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) (t : â„) :
    â€–expBounded (I â€¢ yosidaApprox gen hsa n) tâ€– â‰¤ Real.exp (|t| * â€–I â€¢ yosidaApprox gen hsa nâ€–) :=
  expBounded_norm_bound _ _

/-- Simplified bound using â€–I â€¢ Bâ€– = â€–Bâ€–. -/
theorem expBounded_yosida_norm_le'
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) (t : â„) :
    â€–expBounded (I â€¢ yosidaApprox gen hsa n) tâ€– â‰¤ Real.exp (|t| * â€–yosidaApprox gen hsa nâ€–) := by
  have h := expBounded_norm_bound (I â€¢ yosidaApprox gen hsa n) t
  simp only [norm_smul, Complex.norm_I, one_mul] at h
  exact h



/-- **Summability of Exponential Series**

The power series defining exp(tB) is summable in operator norm.

This is the foundational convergence result enabling the definition of expBounded.
-/
lemma expBounded_summable (B : H â†’L[â„‚] H) (t : â„) :
    Summable (fun k : â„• => (1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B) ^ k) := by
  apply Summable.of_norm
  have h_bound : âˆ€ k, â€–(1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B) ^ kâ€– â‰¤ â€–(t : â„‚) â€¢ Bâ€– ^ k / k.factorial := by
    intro k
    rw [norm_smul]
    calc â€–(1 / k.factorial : â„‚)â€– * â€–((t : â„‚) â€¢ B) ^ kâ€–
        â‰¤ â€–(1 / k.factorial : â„‚)â€– * â€–(t : â„‚) â€¢ Bâ€– ^ k := by
            apply mul_le_mul_of_nonneg_left (opNorm_pow_le _ _)
            exact norm_nonneg _
      _ = (1 / k.factorial) * â€–(t : â„‚) â€¢ Bâ€– ^ k := by
            congr 1
            simp only [norm_div, norm_one, Complex.norm_natCast]
      _ = â€–(t : â„‚) â€¢ Bâ€– ^ k / k.factorial := by ring
  apply Summable.of_nonneg_of_le
  Â· intro k; exact norm_nonneg _
  Â· exact h_bound
  Â· exact Real.summable_pow_div_factorial â€–(t : â„‚) â€¢ Bâ€–



/-- **Adjoint of Powers**

The adjoint distributes over powers:

  (Báµ)* = (B*)áµ

**Proof by induction:**

  - Base: (Bâ°)* = I* = I = (B*)â°
  - Step: (BáµâºÂ¹)* = (Báµ Â· B)* = B* Â· (Báµ)* = B* Â· (B*)áµ = (B*)áµâºÂ¹

The step uses the adjoint reversal rule (ST)* = T*S* and the inductive hypothesis.
-/
theorem adjoint_pow (B : H â†’L[â„‚] H) (k : â„•) :
    (B ^ k).adjoint = B.adjoint ^ k := by
  induction k with
  | zero =>
    simp only [pow_zero]
    ext Ï†
    apply ext_inner_right â„‚
    intro Ïˆ
    rw [ContinuousLinearMap.adjoint_inner_left]
    simp only [ContinuousLinearMap.one_apply]
  | succ k ih =>
    rw [pow_succ, pow_succ]
    ext Ï†
    apply ext_inner_right â„‚
    intro Ïˆ
    rw [ContinuousLinearMap.adjoint_inner_left]
    simp only [ContinuousLinearMap.mul_apply]
    rw [â† ContinuousLinearMap.adjoint_inner_left (B ^ k)]
    rw [ih]
    rw [â† ContinuousLinearMap.adjoint_inner_left B]
    congr 1
    have h_comm : B.adjoint * B.adjoint ^ k = B.adjoint ^ k * B.adjoint := by
      rw [â† pow_succ, â† pow_succ', add_comm]
    calc B.adjoint ((B.adjoint ^ k) Ï†)
        = (B.adjoint * B.adjoint ^ k) Ï† := rfl
      _ = (B.adjoint ^ k * B.adjoint) Ï† := by rw [h_comm]
      _ = (B.adjoint ^ k) (B.adjoint Ï†) := rfl


/-- Helper: evaluation at a point commutes with tsum of operators. -/
lemma tsum_apply_of_summable (f : â„• â†’ H â†’L[â„‚] H) (hf : Summable f) (x : H) :
    (âˆ‘' n, f n) x = âˆ‘' n, f n x := by
  let evalx : (H â†’L[â„‚] H) â†’L[â„‚] H := ContinuousLinearMap.apply â„‚ H x
  calc (âˆ‘' n, f n) x
      = evalx (âˆ‘' n, f n) := rfl
    _ = âˆ‘' n, evalx (f n) := evalx.map_tsum hf
    _ = âˆ‘' n, f n x := rfl

/-- Helper: variant of tsum_apply_of_summable. -/
lemma tsum_apply_of_summable' (f : â„• â†’ H â†’L[â„‚]H) (hf : Summable f) (x : H) :
    (âˆ‘' n, f n) x = âˆ‘' n, f n x := by
  let evalx : (H â†’L[â„‚] H) â†’L[â„‚] H := ContinuousLinearMap.apply â„‚ H x
  calc (âˆ‘' n, f n) x
      = evalx (âˆ‘' n, f n) := rfl
    _ = âˆ‘' n, evalx (f n) := evalx.map_tsum hf
    _ = âˆ‘' n, f n x := rfl


/-- Helper: summability of norms of exponential series terms. -/
lemma expBounded_norm_summable (B : H â†’L[â„‚] H) (t : â„) :
    Summable (fun k : â„• => â€–(1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B) ^ kâ€–) := by
  have h_bound : âˆ€ k, â€–(1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B) ^ kâ€– â‰¤ â€–(t : â„‚) â€¢ Bâ€– ^ k / k.factorial := by
    intro k
    rw [norm_smul]
    calc â€–(1 / k.factorial : â„‚)â€– * â€–((t : â„‚) â€¢ B) ^ kâ€–
        â‰¤ â€–(1 / k.factorial : â„‚)â€– * â€–(t : â„‚) â€¢ Bâ€– ^ k := by
            apply mul_le_mul_of_nonneg_left (opNorm_pow_le _ _) (norm_nonneg _)
      _ = â€–(t : â„‚) â€¢ Bâ€– ^ k / k.factorial := by
            simp only [norm_div, norm_one, Complex.norm_natCast]
            exact one_div_mul_eq_div (â†‘k.factorial) (â€–â†‘t â€¢ Bâ€– ^ k)
  apply Summable.of_nonneg_of_le
  Â· intro k; exact norm_nonneg _
  Â· exact h_bound
  Â· exact Real.summable_pow_div_factorial â€–(t : â„‚) â€¢ Bâ€–

/-- Helper: variant of expBounded_norm_summable. -/
lemma expBounded_norm_summable' (B : H â†’L[â„‚] H) (t : â„) :
    Summable (fun k : â„• => â€–(1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B) ^ kâ€–) := by
  have h_bound : âˆ€ k, â€–(1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B) ^ kâ€– â‰¤ â€–(t : â„‚) â€¢ Bâ€– ^ k / k.factorial := by
    intro k
    rw [norm_smul]
    calc â€–(1 / k.factorial : â„‚)â€– * â€–((t : â„‚) â€¢ B) ^ kâ€–
        â‰¤ â€–(1 / k.factorial : â„‚)â€– * â€–(t : â„‚) â€¢ Bâ€– ^ k := by
            apply mul_le_mul_of_nonneg_left (opNorm_pow_le _ _) (norm_nonneg _)
      _ = â€–(t : â„‚) â€¢ Bâ€– ^ k / k.factorial := by
            simp only [norm_div, norm_one, Complex.norm_natCast]
            simp_all only [one_div, coe_smul]
            exact inv_mul_eq_div (â†‘k.factorial) (â€–t â€¢ Bâ€– ^ k)
  apply Summable.of_nonneg_of_le
  Â· intro k; exact norm_nonneg _
  Â· exact h_bound
  Â· exact Real.summable_pow_div_factorial â€–(t : â„‚) â€¢ Bâ€–

/-- Helper: inner product commutes with tsum in second argument. -/
lemma inner_tsum_right' (x : H) (f : â„• â†’ H) (hf : Summable f) :
    âŸªx, âˆ‘' n, f nâŸ«_â„‚ = âˆ‘' n, âŸªx, f nâŸ«_â„‚ := by
  let L : H â†’L[â„‚] â„‚ := innerSL â„‚ x
  have hL : âˆ€ y, L y = âŸªx, yâŸ«_â„‚ := fun y => rfl
  calc âŸªx, âˆ‘' n, f nâŸ«_â„‚
      = L (âˆ‘' n, f n) := (hL _).symm
    _ = âˆ‘' n, L (f n) := L.map_tsum hf
    _ = âˆ‘' n, âŸªx, f nâŸ«_â„‚ := by simp only [hL]

/-- Helper: inner product commutes with tsum in first argument. -/
lemma tsum_inner_left' (f : â„• â†’ H) (y : H) (hf : Summable f) :
    âŸªâˆ‘' n, f n, yâŸ«_â„‚ = âˆ‘' n, âŸªf n, yâŸ«_â„‚ := by
  have h_conj : âŸªâˆ‘' n, f n, yâŸ«_â„‚ = (starRingEnd â„‚) âŸªy, âˆ‘' n, f nâŸ«_â„‚ :=
    (inner_conj_symm (âˆ‘' n, f n) y).symm
  rw [h_conj, inner_tsum_right' y f hf]
  rw [conj_tsum]
  Â· congr 1
    ext n
    exact (inner_conj_symm (f n) y)

/-- **Adjoint of Exponential**

The adjoint commutes with the exponential:

  (exp(tB))* = exp(tB*)

**Proof:**

Since adjoint is a continuous linear operation and the exponential is defined
by a convergent series:

  (exp(tB))* = (Î£â‚– (tB)áµ/k!)* = Î£â‚– ((tB)áµ/k!)* = Î£â‚– (tB*)áµ/k! = exp(tB*)

The key step uses (Báµ)* = (B*)áµ from `adjoint_pow`.

**Consequence for skew-adjoint operators:**

If B* = -B, then (exp(tB))* = exp(tB*) = exp(-tB), which combined with the
semigroup law gives (exp(tB))*(exp(tB)) = exp(-tB)exp(tB) = exp(0) = I.
-/
theorem adjoint_expBounded (B : H â†’L[â„‚] H) (t : â„) :
    (expBounded B t).adjoint = expBounded B.adjoint t := by
  unfold expBounded

  have h_summable : Summable (fun k : â„• => (1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B) ^ k) :=
    expBounded_summable B t

  have h_summable_adj : Summable (fun k : â„• => (1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B.adjoint) ^ k) :=
    expBounded_summable B.adjoint t

  ext Ï†
  apply ext_inner_right â„‚
  intro Ïˆ

  rw [ContinuousLinearMap.adjoint_inner_left]
  rw [tsum_apply_of_summable _ h_summable Ïˆ]
  rw [tsum_apply_of_summable _ h_summable_adj Ï†]

  have h_inner_summable : Summable (fun k => ((1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B) ^ k) Ïˆ) := by
    apply Summable.of_norm
    have h_norm_sum := expBounded_norm_summable B t
    have h_scaled : Summable (fun k => â€–(1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B) ^ kâ€– * â€–Ïˆâ€–) :=
      h_norm_sum.mul_right â€–Ïˆâ€–
    apply Summable.of_nonneg_of_le
    Â· intro k; exact norm_nonneg _
    Â· intro k
      exact ContinuousLinearMap.le_opNorm _ _
    Â· exact h_scaled

  have h_inner_summable_adj : Summable (fun k => ((1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B.adjoint) ^ k) Ï†) := by
    apply Summable.of_norm
    have h_norm_sum := expBounded_norm_summable B.adjoint t
    have h_scaled : Summable (fun k => â€–(1 / k.factorial : â„‚) â€¢ ((t : â„‚) â€¢ B.adjoint) ^ kâ€– * â€–Ï†â€–) :=
      h_norm_sum.mul_right â€–Ï†â€–
    apply Summable.of_nonneg_of_le
    Â· intro k; exact norm_nonneg _
    Â· intro k
      exact ContinuousLinearMap.le_opNorm _ _
    Â· exact h_scaled

  rw [inner_tsum_right' Ï† _ h_inner_summable]
  rw [tsum_inner_left' _ Ïˆ h_inner_summable_adj]

  congr 1
  ext k

  simp only [ContinuousLinearMap.smul_apply]
  rw [inner_smul_right, inner_smul_left]

  have h_real : (starRingEnd â„‚) (1 / k.factorial : â„‚) = (1 / k.factorial : â„‚) := by
    simp only [map_divâ‚€, map_one, map_natCast]
  rw [h_real]

  congr 1

  have h_smul_pow : âˆ€ (c : â„‚) (T : H â†’L[â„‚] H) (n : â„•), (c â€¢ T) ^ n = c ^ n â€¢ T ^ n := by
    intro c T n
    induction n with
    | zero => simp
    | succ n ih =>
      rw [pow_succ, pow_succ, pow_succ, ih]
      ext x
      simp only [ContinuousLinearMap.mul_apply, ContinuousLinearMap.smul_apply]
      rw [ContinuousLinearMap.map_smul]
      rw [smul_smul]

  rw [h_smul_pow, h_smul_pow]
  simp only [ContinuousLinearMap.smul_apply]
  rw [inner_smul_right, inner_smul_left]

  have h_t_real : (starRingEnd â„‚) ((t : â„‚) ^ k) = (t : â„‚) ^ k := by
    simp only [map_pow, Complex.conj_ofReal]
  rw [h_t_real]

  congr 1

  rw [â† ContinuousLinearMap.adjoint_inner_left (B ^ k)]
  rw [adjoint_pow]


/-- **Exponential of Skew-Adjoint is Unitary**

For skew-adjoint B (i.e., B* = -B), the exponential exp(tB) is unitary:

  (exp(tB))* âˆ˜ exp(tB) = I  and  exp(tB) âˆ˜ (exp(tB))* = I

**Proof:**

1. From B* = -B and `adjoint_expBounded`:
   (exp(tB))* = exp(tB*) = exp(t(-B)) = exp(-tB)

2. From the semigroup law:
   (exp(tB))* âˆ˜ exp(tB) = exp(-tB) âˆ˜ exp(tB) = exp(0) = I
   exp(tB) âˆ˜ (exp(tB))* = exp(tB) âˆ˜ exp(-tB) = exp(0) = I

**Physical significance:**

Skew-adjoint operators generate unitary evolution. In quantum mechanics:
  - The Hamiltonian H is self-adjoint
  - The time evolution generator is iH, which is skew-adjoint
  - Therefore exp(itH) is unitary, preserving probability

**Application to Yosida:**

The symmetrized approximants Aâ‚™Ë¢Ê¸áµ are self-adjoint, so iÂ·Aâ‚™Ë¢Ê¸áµ is skew-adjoint.
Therefore exp(tÂ·iÂ·Aâ‚™Ë¢Ê¸áµ) is unitary for all t and n. This unitarity passes to
the strong limit, establishing that exp(itA) is unitary.
-/
theorem expBounded_skewAdjoint_unitary (B : H â†’L[â„‚] H) (hB : B.adjoint = -B) (t : â„) :
    (expBounded B t).adjoint.comp (expBounded B t) = ContinuousLinearMap.id â„‚ H âˆ§
    (expBounded B t).comp (expBounded B t).adjoint = ContinuousLinearMap.id â„‚ H := by
  -- exp(tB)* = exp(tB*) = exp(t(-B)) = exp(-tB)
  have h_adj : (expBounded B t).adjoint = expBounded B (-t) := by
    rw [adjoint_expBounded]
    rw [hB]
    unfold expBounded
    congr 1
    ext k
    congr 2
    ext x
    simp only [Complex.ofReal_neg, neg_smul, smul_neg]

  constructor
  Â· -- exp(tB)* âˆ˜ exp(tB) = exp(-tB) âˆ˜ exp(tB) = exp(0) = I
    rw [h_adj]
    rw [â† expBounded_group_law B (-t) t]
    simp only [neg_add_cancel]
    unfold expBounded
    simp only [Complex.ofReal_zero, zero_smul]
    have h_eq : (fun k : â„• => (1 / k.factorial : â„‚) â€¢ (0 : H â†’L[â„‚] H) ^ k) =
                (fun k : â„• => if k = 0 then 1 else 0) := by
      ext k
      cases k with
      | zero => simp
      | succ k => simp [pow_succ]
    rw [h_eq]
    rw [tsum_eq_single 0]
    Â· abel
    Â· intro k hk
      simp [hk]

  Â· -- exp(tB) âˆ˜ exp(tB)* = exp(tB) âˆ˜ exp(-tB) = exp(0) = I
    rw [h_adj]
    rw [â† expBounded_group_law B t (-t)]
    simp only [add_neg_cancel]
    unfold expBounded
    simp only [Complex.ofReal_zero, zero_smul]
    have h_eq : (fun k : â„• => (1 / k.factorial : â„‚) â€¢ (0 : H â†’L[â„‚] H) ^ k) =
                (fun k : â„• => if k = 0 then 1 else 0) := by
      ext k
      cases k with
      | zero => simp
      | succ k => simp [pow_succ]
    rw [h_eq]
    rw [tsum_eq_single 0]
    Â· abel
    Â· intro k hk
      simp [hk]

/-!
============================================================================================================================
## Section 7: Unitarity of Yosida Exponentials
============================================================================================================================

The exponentials exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ) of the symmetrized Yosida approximants are unitary
operators. This follows from the chain:

  Aâ‚™Ë¢Ê¸áµ self-adjoint âŸ¹ IÂ·Aâ‚™Ë¢Ê¸áµ skew-adjoint âŸ¹ exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ) unitary

Unitarity means these operators:
  1. Preserve inner products: âŸ¨UÏˆ, UÏ†âŸ© = âŸ¨Ïˆ, Ï†âŸ©
  2. Are isometries: â€–UÏˆâ€– = â€–Ïˆâ€–
  3. Are invertible with Uâ»Â¹ = U*

This unitarity is essential for the Yosida construction: it ensures the approximating
sequence has uniformly bounded norms (all equal to 1), enabling the strong limit
to exist and be unitary.
-/

/-- **Yosida Exponentials Preserve Inner Products**

The exponential exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ) preserves inner products:

  âŸ¨exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ïˆ, exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ï†âŸ© = âŸ¨Ïˆ, Ï†âŸ©

**Proof:**

1. IÂ·Aâ‚™Ë¢Ê¸áµ is skew-adjoint (from `I_smul_yosidaApproxSym_skewAdjoint`)
2. Skew-adjoint operators have unitary exponentials (from `expBounded_skewAdjoint_unitary`)
3. Unitary operators preserve inner products: âŸ¨UÏˆ, UÏ†âŸ© = âŸ¨Ïˆ, U*UÏ†âŸ© = âŸ¨Ïˆ, Ï†âŸ©

**Role in the construction:**

Inner product preservation passes to limits. Since each approximant preserves
inner products, and the inner product is continuous, the limiting operator
exp(itA) also preserves inner products â€” establishing its unitarity.
-/
theorem expBounded_yosidaApproxSym_unitary
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) (t : â„) (Ïˆ Ï† : H) :
    âŸªexpBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ,
     expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†âŸ«_â„‚ = âŸªÏˆ, Ï†âŸ«_â„‚ := by
  have h_skew := I_smul_yosidaApproxSym_skewAdjoint gen hsa n
  have h_unitary := expBounded_skewAdjoint_unitary (I â€¢ yosidaApproxSym gen hsa n) h_skew t
  let U := expBounded (I â€¢ yosidaApproxSym gen hsa n) t

  calc âŸªU Ïˆ, U Ï†âŸ«_â„‚
      = âŸªÏˆ, U.adjoint (U Ï†)âŸ«_â„‚ := (ContinuousLinearMap.adjoint_inner_right U Ïˆ (U Ï†)).symm
    _ = âŸªÏˆ, (U.adjoint.comp U) Ï†âŸ«_â„‚ := rfl
    _ = âŸªÏˆ, (ContinuousLinearMap.id â„‚ H) Ï†âŸ«_â„‚ := by rw [h_unitary.1]
    _ = âŸªÏˆ, Ï†âŸ«_â„‚ := by simp


/-- **Yosida Exponentials are Isometries**

The exponential exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ) preserves norms:

  â€–exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ïˆâ€– = â€–Ïˆâ€–

**Proof:**

From inner product preservation with Ï† = Ïˆ:
  â€–UÏˆâ€–Â² = âŸ¨UÏˆ, UÏˆâŸ© = âŸ¨Ïˆ, ÏˆâŸ© = â€–Ïˆâ€–Â²

Taking square roots (both sides non-negative): â€–UÏˆâ€– = â€–Ïˆâ€–.

**Significance:**

Isometry is the key property used in the Cauchy sequence argument. When showing
exp(tÂ·IÂ·Aâ‚˜Ë¢Ê¸áµ)Ïˆ - exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ïˆ is small, we use:

  â€–exp(tÂ·IÂ·Aâ‚˜Ë¢Ê¸áµ)(Ïˆ - Ï†)â€– = â€–Ïˆ - Ï†â€–

This allows approximation by domain elements without worrying about operator norms.
-/
theorem expBounded_yosidaApproxSym_isometry
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) (t : â„) (Ïˆ : H) :
    â€–expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆâ€– = â€–Ïˆâ€– := by
  set U := expBounded (I â€¢ yosidaApproxSym gen hsa n) t with hU
  have h_inner := expBounded_yosidaApproxSym_unitary gen hsa n t Ïˆ Ïˆ
  have h1 : â€–U Ïˆâ€–^2 = re âŸªU Ïˆ, U ÏˆâŸ«_â„‚ := (inner_self_eq_norm_sq (ğ•œ := â„‚) (U Ïˆ)).symm
  have h2 : â€–Ïˆâ€–^2 = re âŸªÏˆ, ÏˆâŸ«_â„‚ := (inner_self_eq_norm_sq (ğ•œ := â„‚) Ïˆ).symm
  have h_sq : â€–U Ïˆâ€–^2 = â€–Ïˆâ€–^2 := by
    rw [h1, h2, h_inner]
  have h_nonneg1 : 0 â‰¤ â€–U Ïˆâ€– := norm_nonneg _
  have h_nonneg2 : 0 â‰¤ â€–Ïˆâ€– := norm_nonneg _
  nlinarith [sq_nonneg (â€–U Ïˆâ€– - â€–Ïˆâ€–), sq_nonneg (â€–U Ïˆâ€– + â€–Ïˆâ€–), h_sq, h_nonneg1, h_nonneg2]





/-!
============================================================================================================================
## Section 8: Convergence and the Exponential Definition
============================================================================================================================

We now establish that the Yosida exponentials form a Cauchy sequence, enabling
the definition of exp(itA) as their strong limit.

**The convergence argument:**

For Ïˆ âˆˆ H and Îµ > 0:
1. Approximate Ïˆ by Ï† âˆˆ D(A) with â€–Ïˆ - Ï†â€– < Îµ/3
2. On domain elements, use the Duhamel formula to show exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ï† â†’ U(t)Ï†
3. Use isometry to control â€–exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)(Ïˆ - Ï†)â€– = â€–Ïˆ - Ï†â€–

**The Duhamel formula:**

For Ï† âˆˆ D(A), the difference between the true evolution and the approximation is:

  U(t)Ï† - exp(tBâ‚™)Ï† = âˆ«â‚€áµ— exp((t-s)Bâ‚™)(iA - Bâ‚™)U(s)Ï† ds

where Bâ‚™ = IÂ·Aâ‚™Ë¢Ê¸áµ. Since exp((t-s)Bâ‚™) is an isometry:

  â€–U(t)Ï† - exp(tBâ‚™)Ï†â€– â‰¤ |t| Â· sup_{sâˆˆ[0,|t|]} â€–(A - Aâ‚™Ë¢Ê¸áµ)U(s)Ï†â€–

The RHS â†’ 0 as n â†’ âˆ by uniform convergence of Aâ‚™Ë¢Ê¸áµ â†’ A on the orbit {U(s)Ï†}.

**Definition of exp(itA):**

With Cauchy sequences established, we define:

  exp(itA) := s-lim_{nâ†’âˆ} exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)

This is the strong operator limit, existing by completeness of H.
-/


/-!
================================================================================
SECTION X: UNIFORM CONVERGENCE ON COMPACT ORBITS
================================================================================

The final piece needed for the convergence theorem.
-/

section UniformConvergence

open StonesTheorem.Resolvent StonesTheorem.Exponential

variable (U_grp : OneParameterUnitaryGroup (H := H))
variable (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
variable (h_dense : Dense (gen.domain : Set H))

/-- The orbit {U(s)Ï† : s âˆˆ [0, |t|]} is compact. -/
lemma orbit_compact (t : â„) (Ï† : H) :
    IsCompact {Ïˆ : H | âˆƒ s âˆˆ Set.Icc 0 |t|, Ïˆ = U_grp.U s Ï†} := by
  -- Continuous image of compact set [0, |t|]
  sorry

/-- The Yosida approximants are equicontinuous (uniformly bounded). -/
lemma yosidaApproxSym_equicontinuous :
    âˆ€ n : â„•+, â€–yosidaApproxSym gen hsa nâ€– â‰¤ 2 * n := by
  sorry

/-- Pointwise convergence of Yosida approximants on the domain. -/
lemma yosidaApproxSym_pointwise
    (h_dense : Dense (gen.domain : Set H))
    (Ïˆ : H) (hÏˆ : Ïˆ âˆˆ gen.domain) :
    Tendsto (fun n : â„•+ => yosidaApproxSym gen hsa n Ïˆ) atTop (ğ“ (gen.op Ïˆ)) := by
  exact yosidaApproxSym_tendsto_on_domain gen hsa h_dense Ïˆ hÏˆ

/-- **Uniform Convergence on Orbit**

For Ï† âˆˆ D(A), the Yosida approximants converge uniformly to A on the orbit.
-/
theorem yosidaApproxSym_uniform_on_orbit (t : â„) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    Tendsto (fun n : â„•+ => â¨† s âˆˆ Set.Icc 0 |t|,
              â€–(gen.op - yosidaApproxSym gen hsa n) (U_grp.U s Ï†)â€–)
            atTop (ğ“ 0) := by
  -- Strategy:
  -- 1. The orbit K = {U(s)Ï† : s âˆˆ [0,|t|]} is compact
  -- 2. U(s)Ï† âˆˆ D(A) for all s (domain invariance)
  -- 3. Aâ‚™(Ïˆ) â†’ A(Ïˆ) pointwise for all Ïˆ âˆˆ D(A)
  -- 4. {Aâ‚™} is equicontinuous (uniformly bounded)
  -- 5. Apply ArzelÃ -Ascoli / equicontinuity argument:
  --    pointwise convergence + equicontinuity on compact = uniform convergence
  sorry

end UniformConvergence


/-- **Exponential at t=0 is Identity**

For any bounded operator B: exp(0Â·B) = I.

**Proof:**

The power series at t=0 collapses:
  exp(0Â·B) = Î£â‚– (0Â·B)áµ/k! = (0Â·B)â°/0! + Î£â‚–â‰¥â‚ 0áµÂ·Báµ/k! = I + 0 = I
-/
lemma expBounded_at_zero (B : H â†’L[â„‚] H) (Ïˆ : H) :
    expBounded B 0 Ïˆ = Ïˆ := by
  unfold expBounded
  simp only [one_div, ofReal_zero, zero_smul]

  have h_zero_pow : âˆ€ k : â„•, (0 : H â†’L[â„‚] H) ^ k = if k = 0 then 1 else 0 := by
    intro k
    cases k with
    | zero => simp [pow_zero]
    | succ k => simp [pow_succ, mul_zero]

  simp_rw [h_zero_pow]
  have h_sum : (âˆ‘' k : â„•, (1 / k.factorial : â„‚) â€¢ (if k = 0 then (1 : H â†’L[â„‚] H) else 0)) = 1 := by
    rw [tsum_eq_single 0]
    Â· simp [Nat.factorial_zero]
    Â· intro k hk
      simp [hk]
  simp only [smul_ite, smul_zero]
  simp_all only [one_div, smul_ite, Nat.factorial_zero, Nat.cast_one, inv_one, one_smul, smul_zero, tsum_ite_eq,
    ContinuousLinearMap.one_apply]



/-- **Unitary Group at t=0**

U(0) = I for any one-parameter unitary group.

This is part of the group axioms: U(0) = U(t + (-t)) = U(t)U(-t) requires U(0) = I.
-/
lemma unitary_group_at_zero
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (Ïˆ : H) :
    U_grp.U 0 Ïˆ = Ïˆ := by
  rw [U_grp.identity]
  simp only [ContinuousLinearMap.id_apply]


/-- **Domain Invariance under Unitary Group**

If Ï† âˆˆ D(A), then U(t)Ï† âˆˆ D(A) for all t âˆˆ â„.

**Physical meaning:**

The domain of the Hamiltonian is preserved under time evolution. States that
are "smooth enough" to be in D(A) remain smooth under the dynamics generated by A.

**Mathematical role:**

This invariance is essential for the Duhamel formula: we need A(U(s)Ï†) to be
defined for all s âˆˆ [0,t], which requires U(s)Ï† âˆˆ D(A).
-/
lemma unitary_group_domain_invariant
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp)
    (t : â„) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    U_grp.U t Ï† âˆˆ gen.domain :=
  gen.domain_invariant t Ï† hÏ†



/-- **Generator Commutes with Unitary Group**

For Ï† âˆˆ D(A): A(U(t)Ï†) = U(t)(AÏ†)

**Derivation:**

Both sides are well-defined since U(t)Ï† âˆˆ D(A) by domain invariance and AÏ† âˆˆ H.

The identity follows from the group law and the definition of the generator:

  A(U(t)Ï†) = lim_{sâ†’0} (U(s)U(t)Ï† - U(t)Ï†)/(is)
           = lim_{sâ†’0} (U(t+s)Ï† - U(t)Ï†)/(is)
           = lim_{sâ†’0} U(t)((U(s)Ï† - Ï†)/(is))
           = U(t) Â· lim_{sâ†’0} (U(s)Ï† - Ï†)/(is)
           = U(t)(AÏ†)

The interchange of U(t) with the limit uses continuity of U(t).

**Physical interpretation:**

Time evolution commutes with the Hamiltonian on domain elements. This is the
infinitesimal version of [U(t), A] = 0, reflecting that A is conserved under
its own time evolution.
-/
lemma generator_commutes_unitary
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp)
    (t : â„) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    gen.op (U_grp.U t Ï†) = U_grp.U t (gen.op Ï†) := by
  have hUtÏ† : U_grp.U t Ï† âˆˆ gen.domain := gen.domain_invariant t Ï† hÏ†
  have h_gen_UtÏ† := gen.generator_formula (U_grp.U t Ï†) hUtÏ†
  have h_gen_Ï† := gen.generator_formula Ï† hÏ†

  have h_key : âˆ€ s : â„, U_grp.U s (U_grp.U t Ï†) - U_grp.U t Ï† = U_grp.U t (U_grp.U s Ï† - Ï†) := by
    intro s
    have h1 : U_grp.U s (U_grp.U t Ï†) = U_grp.U (s + t) Ï† := by
      rw [U_grp.group_law]
      rfl
    have h2 : U_grp.U (s + t) Ï† = U_grp.U (t + s) Ï† := by
      rw [add_comm]
    have h3 : U_grp.U (t + s) Ï† = U_grp.U t (U_grp.U s Ï†) := by
      rw [U_grp.group_law]
      rfl
    calc U_grp.U s (U_grp.U t Ï†) - U_grp.U t Ï†
        = U_grp.U t (U_grp.U s Ï†) - U_grp.U t Ï† := by rw [h1, h2, h3]
      _ = U_grp.U t (U_grp.U s Ï†) - U_grp.U t Ï† := rfl
      _ = U_grp.U t (U_grp.U s Ï† - Ï†) := by rw [ContinuousLinearMap.map_sub]

  have h_eq_seq : âˆ€ s : â„, (I * s)â»Â¹ â€¢ (U_grp.U s (U_grp.U t Ï†) - U_grp.U t Ï†) =
                          U_grp.U t ((I * s)â»Â¹ â€¢ (U_grp.U s Ï† - Ï†)) := by
    intro s
    rw [h_key s, ContinuousLinearMap.map_smul]

  have h_rhs_tendsto : Tendsto (fun s : â„ => U_grp.U t ((I * (s : â„‚))â»Â¹ â€¢ (U_grp.U s Ï† - Ï†)))
                               (ğ“[â‰ ] 0) (ğ“ (U_grp.U t (gen.op Ï†))) := by
    apply Filter.Tendsto.comp (U_grp.U t).continuous.continuousAt h_gen_Ï†

  have h_limits_eq := tendsto_nhds_unique h_gen_UtÏ† (h_rhs_tendsto.congr (fun s => (h_eq_seq s).symm))
  exact h_limits_eq




/-
# MASSIVE TO-DO!!!
-/
/-!
================================================================================
SECTION 6: DUHAMEL FORMULA
================================================================================

The variation of parameters formula for comparing U(t) with exp(tB).
-/

section DuhamelFormula

open StonesTheorem.Resolvent
variable (U_grp : OneParameterUnitaryGroup (H := H))
variable (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
variable (h_dense : Dense (gen.domain : Set H))

/-- The integrand in the Duhamel formula:
    f(s) = exp((t-s)B) Â· (iA - B) Â· U(s)Ï†
where B = iÂ·Aâ‚™Ë¢Ê¸áµ -/
noncomputable def duhamelIntegrand
    (n : â„•+) (t : â„) (Ï† : H) (s : â„) : H :=
  expBounded (I â€¢ yosidaApproxSym gen hsa n) (t - s)
    ((I â€¢ gen.op - I â€¢ yosidaApproxSym gen hsa n) (U_grp.U s Ï†))

/-- The integrand is continuous in s. -/
lemma duhamelIntegrand_continuous (n : â„•+) (t : â„) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    Continuous (duhamelIntegrand U_grp gen hsa n t Ï†) := by
  sorry

/-- The integrand is bounded. -/
lemma duhamelIntegrand_bound (n : â„•+) (t : â„) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) (s : â„)
    (hs : s âˆˆ Set.Icc 0 |t|) :
    â€–duhamelIntegrand U_grp gen hsa n t Ï† sâ€– â‰¤
    â€–(I â€¢ gen.op - I â€¢ yosidaApproxSym gen hsa n) (U_grp.U s Ï†)â€– := by
  -- Uses that exp((t-s)B) is an isometry
  sorry

/-- The Duhamel formula as an integral identity.

For Ï† âˆˆ D(A):
  U(t)Ï† - exp(tÂ·iÂ·Aâ‚™Ë¢Ê¸áµ)Ï† = âˆ«â‚€áµ— exp((t-s)Â·iÂ·Aâ‚™Ë¢Ê¸áµ) Â· iÂ·(A - Aâ‚™Ë¢Ê¸áµ) Â· U(s)Ï† ds

This is proven by showing the integrand is the derivative of
  s â†¦ exp((t-s)Â·iÂ·Aâ‚™Ë¢Ê¸áµ) Â· U(s)Ï†
-/
theorem duhamel_identity (n : â„•+) (t : â„) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    U_grp.U t Ï† - expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï† =
    âˆ« s in Set.Ioc 0 t, duhamelIntegrand U_grp gen hsa n t Ï† s := by
  sorry


/-- **Duhamel Estimate for Yosida Exponentials**

For Ï† âˆˆ D(A) and t âˆˆ â„:

  â€–U(t)Ï† - exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ï†â€– â‰¤ |t| Â· sup_{sâˆˆ[0,|t|]} â€–(A - Aâ‚™Ë¢Ê¸áµ)(U(s)Ï†)â€–

**The Duhamel formula:**

Let Bâ‚™ = IÂ·Aâ‚™Ë¢Ê¸áµ. Define f : [0,t] â†’ H by f(s) = exp((t-s)Bâ‚™)(U(s)Ï†).

Differentiating (using product rule for operator-valued functions):
  f'(s) = -Bâ‚™ exp((t-s)Bâ‚™)(U(s)Ï†) + exp((t-s)Bâ‚™)(iAÂ·U(s)Ï†)
        = exp((t-s)Bâ‚™)(iA - Bâ‚™)(U(s)Ï†)

Boundary values:
  f(0) = exp(tBâ‚™)Ï†
  f(t) = exp(0)U(t)Ï† = U(t)Ï†

Fundamental theorem of calculus:
  U(t)Ï† - exp(tBâ‚™)Ï† = f(t) - f(0) = âˆ«â‚€áµ— f'(s) ds
                    = âˆ«â‚€áµ— exp((t-s)Bâ‚™)(iA - Bâ‚™)(U(s)Ï†) ds

Taking norms and using â€–exp((t-s)Bâ‚™)â€– = 1 (isometry):
  â€–U(t)Ï† - exp(tBâ‚™)Ï†â€– â‰¤ âˆ«â‚€áµ— â€–(A - Aâ‚™Ë¢Ê¸áµ)(U(s)Ï†)â€– ds
                      â‰¤ |t| Â· sup_{sâˆˆ[0,|t|]} â€–(A - Aâ‚™Ë¢Ê¸áµ)(U(s)Ï†)â€–

**AXIOMATIZED:** Requires Bochner integration machinery for operator-valued functions.
-/
lemma duhamel_estimate
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (n : â„•+) (t : â„) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    â€–U_grp.U t Ï† - expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†â€– â‰¤
    |t| * â¨† (s : Set.Icc 0 |t|), â€–gen.op (U_grp.U s Ï†) - yosidaApproxSym gen hsa n (U_grp.U s Ï†)â€– := by
  sorry
/-- **Duhamel Estimate**

The error between U(t) and the Yosida exponential is controlled by the
supremum of the approximation error on the orbit.
-/
theorem duhamel_estimate' (n : â„•+) (t : â„) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    â€–U_grp.U t Ï† - expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†â€– â‰¤
    |t| * â¨† s âˆˆ Set.Icc 0 |t|, â€–(gen.op - yosidaApproxSym gen hsa n) (U_grp.U s Ï†)â€– := by
  sorry

end DuhamelFormula
/-- **Uniform Convergence of Approximant on Orbit**

For Ï† âˆˆ D(A), the approximants converge uniformly on the orbit {U(s)Ï† : s âˆˆ [0,|t|]}:

  sup_{sâˆˆ[0,|t|]} â€–(A - Aâ‚™Ë¢Ê¸áµ)(U(s)Ï†)â€– â†’ 0 as n â†’ âˆ

**Proof outline:**

1. **Domain invariance:** U(s)Ï† âˆˆ D(A) for all s (from `unitary_group_domain_invariant`)

2. **Pointwise convergence:** Aâ‚™Ë¢Ê¸áµ(U(s)Ï†) â†’ A(U(s)Ï†) for each s
   (from `yosidaApproxSym_tendsto_on_domain`)

3. **Compactness:** The orbit {U(s)Ï† : s âˆˆ [0,|t|]} is compact
   (continuous image of compact interval)

4. **Continuity:** s â†¦ A(U(s)Ï†) = U(s)(AÏ†) is continuous
   (from `generator_commutes_unitary` and strong continuity of U)

5. **Dini's theorem:** Pointwise convergence of continuous functions on compact
   set with monotone convergence implies uniform convergence

**AXIOMATIZED:** Requires careful handling of compactness and uniform convergence.
-/
lemma yosidaApproxSym_uniform_convergence_on_orbit
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (h_dense : Dense (gen.domain : Set H))
    (t : â„) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    Tendsto (fun n : â„•+ => â¨† (s : Set.Icc 0 |t|),
             â€–gen.op (U_grp.U s Ï†) - yosidaApproxSym gen hsa n (U_grp.U s Ï†)â€–)
            atTop (ğ“ 0) := by
  sorry

/-- **Yosida Exponentials Converge to Unitary Group on Domain**

For Ï† âˆˆ D(A):

  exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ï† â†’ U(t)Ï†  as n â†’ âˆ

**Proof:**

Combining `duhamel_estimate` and `yosidaApproxSym_uniform_convergence_on_orbit`:

  â€–exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ï† - U(t)Ï†â€– â‰¤ |t| Â· sup_s â€–(A - Aâ‚™Ë¢Ê¸áµ)(U(s)Ï†)â€– â†’ 0

**Role in the construction:**

This is the key convergence result on the domain. Combined with:
  - Density of D(A) in H
  - Isometry of the approximating exponentials

we obtain convergence on all of H (via the Cauchy sequence argument).
-/
lemma expBounded_yosidaApproxSym_tendsto_unitary
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (h_dense : Dense (gen.domain : Set H))
    (t : â„) (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    Tendsto (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†)
            atTop (ğ“ (U_grp.U t Ï†)) := by

  by_cases ht : t = 0
  Â· simp only [ht]
    have h_exp_zero : âˆ€ n : â„•+, expBounded (I â€¢ yosidaApproxSym gen hsa n) 0 Ï† = Ï† :=
      fun n => expBounded_at_zero _ Ï†
    have h_U_zero : U_grp.U 0 Ï† = Ï† := unitary_group_at_zero Ï†
    simp_rw [h_exp_zero, h_U_zero]
    exact tendsto_const_nhds

  Â· apply Metric.tendsto_atTop.mpr
    intro Îµ hÎµ

    have h_unif := yosidaApproxSym_uniform_convergence_on_orbit gen hsa h_dense t Ï† hÏ†
    rw [Metric.tendsto_atTop] at h_unif

    have ht_pos : 0 < |t| + 1 := by linarith [abs_nonneg t]
    have hÎµt : Îµ / (|t| + 1) > 0 := div_pos hÎµ ht_pos
    obtain âŸ¨N, hNâŸ© := h_unif (Îµ / (|t| + 1)) hÎµt

    use N
    intro n hn
    rw [dist_eq_norm]

    calc â€–expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï† - U_grp.U t Ï†â€–
        = â€–U_grp.U t Ï† - expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†â€– := norm_sub_rev _ _
      _ â‰¤ |t| * â¨† (s : Set.Icc 0 |t|), â€–gen.op (U_grp.U s Ï†) - yosidaApproxSym gen hsa n (U_grp.U s Ï†)â€– :=
          duhamel_estimate gen hsa n t Ï† hÏ†
      _ < |t| * (Îµ / (|t| + 1)) := by
          apply mul_lt_mul_of_pos_left _ (abs_pos.mpr ht)
          specialize hN n hn
          simp only [dist_zero_right, Real.norm_eq_abs] at hN
          rw [abs_of_nonneg] at hN
          Â· exact hN
          Â· apply Real.iSup_nonneg
            intro s
            exact norm_nonneg _
      _ < (|t| + 1) * (Îµ / (|t| + 1)) := by
          apply mul_lt_mul_of_pos_right _ hÎµt
          linarith
      _ = Îµ := mul_div_cancelâ‚€ Îµ (ne_of_gt ht_pos)


/-- **Yosida Exponentials Form a Cauchy Sequence**

For any Ïˆ âˆˆ H and t âˆˆ â„, the sequence {exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ïˆ}_{nâ‰¥1} is Cauchy.

**Proof (Îµ/3 argument):**

Given Îµ > 0:

1. **Approximate by domain:** Choose Ï† âˆˆ D(A) with â€–Ïˆ - Ï†â€– < Îµ/3

2. **Cauchy on domain:** The sequence exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ï† converges to U(t)Ï†
   (by `expBounded_yosidaApproxSym_tendsto_unitary`), hence is Cauchy.
   Choose N such that m,n â‰¥ N âŸ¹ â€–exp(...)_m Ï† - exp(...)_n Ï†â€– < Îµ/3

3. **Triangle inequality:** For m,n â‰¥ N:
```
   â€–exp(...)_m Ïˆ - exp(...)_n Ïˆâ€–
     â‰¤ â€–exp(...)_m (Ïˆ - Ï†)â€– + â€–exp(...)_m Ï† - exp(...)_n Ï†â€– + â€–exp(...)_n (Ï† - Ïˆ)â€–
     = â€–Ïˆ - Ï†â€– + â€–exp(...)_m Ï† - exp(...)_n Ï†â€– + â€–Ï† - Ïˆâ€–    [isometry]
     < Îµ/3 + Îµ/3 + Îµ/3 = Îµ
```

**Significance:**

This Cauchy property, combined with completeness of H, ensures the strong limit
exists. We can then define exp(itA)Ïˆ := lim_n exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ïˆ.
-/
theorem expBounded_yosidaApproxSym_cauchy
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (h_dense : Dense (gen.domain : Set H))
    (t : â„) (Ïˆ : H) :
    CauchySeq (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ) := by
  rw [Metric.cauchySeq_iff]
  intro Îµ hÎµ

  have hÎµ3 : Îµ / 3 > 0 := by linarith

  obtain âŸ¨Ï†, hÏ†_mem, hÏ†_closeâŸ© := Metric.mem_closure_iff.mp
    (h_dense.closure_eq â–¸ Set.mem_univ Ïˆ) (Îµ / 3) hÎµ3
  rw [dist_eq_norm] at hÏ†_close

  have h_cauchy_Ï† : CauchySeq (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†) := by
    apply Filter.Tendsto.cauchySeq
    exact expBounded_yosidaApproxSym_tendsto_unitary gen hsa h_dense t Ï† hÏ†_mem

  rw [Metric.cauchySeq_iff] at h_cauchy_Ï†
  obtain âŸ¨N, hNâŸ© := h_cauchy_Ï† (Îµ / 3) hÎµ3

  use N
  intro m hm n hn
  rw [dist_eq_norm]

  calc â€–expBounded (I â€¢ yosidaApproxSym gen hsa m) t Ïˆ -
        expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆâ€–
      = â€–(expBounded (I â€¢ yosidaApproxSym gen hsa m) t Ïˆ - expBounded (I â€¢ yosidaApproxSym gen hsa m) t Ï†) +
         (expBounded (I â€¢ yosidaApproxSym gen hsa m) t Ï† - expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†) +
         (expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï† - expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ)â€– := by
          congr 1; abel
    _ â‰¤ â€–expBounded (I â€¢ yosidaApproxSym gen hsa m) t Ïˆ - expBounded (I â€¢ yosidaApproxSym gen hsa m) t Ï†â€– +
        â€–expBounded (I â€¢ yosidaApproxSym gen hsa m) t Ï† - expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†â€– +
        â€–expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï† - expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆâ€– := by
          apply le_trans (norm_add_le _ _)
          apply add_le_add_right
          exact norm_add_le _ _
    _ = â€–expBounded (I â€¢ yosidaApproxSym gen hsa m) t (Ïˆ - Ï†)â€– +
        â€–expBounded (I â€¢ yosidaApproxSym gen hsa m) t Ï† - expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†â€– +
        â€–expBounded (I â€¢ yosidaApproxSym gen hsa n) t (Ï† - Ïˆ)â€– := by
          congr 1
          Â· congr 1
            Â· rw [â† ContinuousLinearMap.map_sub]
          Â· rw [â† ContinuousLinearMap.map_sub]
    _ = â€–Ïˆ - Ï†â€– +
        â€–expBounded (I â€¢ yosidaApproxSym gen hsa m) t Ï† - expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†â€– +
        â€–Ï† - Ïˆâ€– := by
          congr 1
          Â· congr 1
            Â· exact expBounded_yosidaApproxSym_isometry gen hsa m t (Ïˆ - Ï†)
          Â· exact expBounded_yosidaApproxSym_isometry gen hsa n t (Ï† - Ïˆ)
    _ < Îµ / 3 + Îµ / 3 + Îµ / 3 := by
          apply add_lt_add
          apply add_lt_add
          Â· exact hÏ†_close
          Â· rw [â† dist_eq_norm]; exact hN m hm n hn
          Â· rw [norm_sub_rev]; exact hÏ†_close
    _ = Îµ := by ring


/-- **Definition of exp(itA)**

The exponential of itA for self-adjoint A, defined as the strong operator limit
of the symmetrized Yosida approximants:

  exp(itA) := s-lim_{nâ†’âˆ} exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)

**Existence:**

The limit exists because:
  1. For each Ïˆ âˆˆ H, {exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ïˆ} is Cauchy (by `expBounded_yosidaApproxSym_cauchy`)
  2. H is complete, so Cauchy sequences converge
  3. The limit defines a bounded linear operator (uniform boundedness principle)

**Properties (proved below):**
  - Unitary: âŸ¨exp(itA)Ïˆ, exp(itA)Ï†âŸ© = âŸ¨Ïˆ, Ï†âŸ©
  - Group law: exp(i(s+t)A) = exp(isA) âˆ˜ exp(itA)
  - Identity: exp(0) = I
  - Strong continuity: t â†¦ exp(itA)Ïˆ is continuous
  - Generator: d/dt[exp(itA)Ïˆ]|_{t=0} = iAÏˆ for Ïˆ âˆˆ D(A)

**This completes Stone's theorem:** Every self-adjoint operator A generates a
strongly continuous one-parameter unitary group exp(itA), and conversely.
-/
noncomputable def exponential
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (t : â„) : H â†’L[â„‚] H :=
  limUnder atTop (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) t)



/-!
============================================================================================================================
## Section 9: Properties of the Exponential
============================================================================================================================

We verify that the exponential exp(itA) defined via Yosida approximation satisfies
all the properties required of a strongly continuous one-parameter unitary group:

1. **Unitarity:** exp(itA) preserves inner products (hence norms)
2. **Group law:** exp(i(s+t)A) = exp(isA) âˆ˜ exp(itA)
3. **Identity:** exp(0) = I
4. **Strong continuity:** t â†¦ exp(itA)Ïˆ is continuous for each Ïˆ
5. **Generator:** The generator of this group is A itself

These properties are inherited from the approximating sequence by taking limits,
using continuity of the relevant operations (inner product, composition, etc.).

**Completing Stone's theorem:**

The results in this section, combined with the construction, establish:

  **Stone's Theorem:** There is a bijective correspondence between:
    - Self-adjoint operators A on H
    - Strongly continuous one-parameter unitary groups U(t) on H

  Given by: A â†¦ (t â†¦ exp(itA)) and U â†¦ (its generator)
-/

/-- **Pointwise Convergence of Exponential**

The exponential applied to Ïˆ equals the pointwise limit:

  exponential t Ïˆ = lim_n exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ïˆ

This relates the operator-level `limUnder` definition to pointwise convergence.
-/
lemma exponential_tendsto
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (h_dense : Dense (gen.domain : Set H))
    (t : â„) (Ïˆ : H) :
    Tendsto (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ)
            atTop (ğ“ (exponential gen hsa t Ïˆ)) := by
  sorry


/-- **Exponential is Unitary**

The exponential preserves inner products:

  âŸ¨exp(itA)Ïˆ, exp(itA)Ï†âŸ© = âŸ¨Ïˆ, Ï†âŸ©

**Proof:**

Each approximant preserves inner products (by `expBounded_yosidaApproxSym_unitary`):
  âŸ¨exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ïˆ, exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ï†âŸ© = âŸ¨Ïˆ, Ï†âŸ©

The inner product is continuous in both arguments:
  âŸ¨exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ïˆ, exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ï†âŸ© â†’ âŸ¨exp(itA)Ïˆ, exp(itA)Ï†âŸ©

The sequence is constantly âŸ¨Ïˆ, Ï†âŸ©, so the limit is âŸ¨Ïˆ, Ï†âŸ©.

**Physical significance:**

Unitarity means probability is conserved under time evolution. In quantum
mechanics, |âŸ¨Ï†|ÏˆâŸ©|Â² is the probability of measuring state Ïˆ in state Ï†.
Unitarity ensures these probabilities are preserved.
-/
theorem exponential_unitary
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (h_dense : Dense (gen.domain : Set H))
    (t : â„) (Ïˆ Ï† : H) :
    âŸªexponential gen hsa t Ïˆ, exponential gen hsa t Ï†âŸ«_â„‚ = âŸªÏˆ, Ï†âŸ«_â„‚ := by
  have h_conv_Ïˆ : Tendsto (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ)
                          atTop (ğ“ (exponential gen hsa t Ïˆ)) := by
    unfold exponential
    have h_eval : Continuous (fun T : H â†’L[â„‚] H => T Ïˆ) :=
      (ContinuousLinearMap.apply â„‚ H Ïˆ).continuous
    exact exponential_tendsto gen hsa h_dense t Ïˆ

  have h_conv_Ï† : Tendsto (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†)
                          atTop (ğ“ (exponential gen hsa t Ï†)) := by
    unfold exponential
    have h_eval : Continuous (fun T : H â†’L[â„‚] H => T Ï†) :=
      (ContinuousLinearMap.apply â„‚ H Ï†).continuous
    exact exponential_tendsto gen hsa h_dense t Ï†

  have h_approx_unitary : âˆ€ n : â„•+,
      âŸªexpBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ,
       expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†âŸ«_â„‚ = âŸªÏˆ, Ï†âŸ«_â„‚ :=
    fun n => expBounded_yosidaApproxSym_unitary gen hsa n t Ïˆ Ï†

  have h_inner_cont : Tendsto (fun n : â„•+ =>
      âŸªexpBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ,
       expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†âŸ«_â„‚)
      atTop (ğ“ âŸªexponential gen hsa t Ïˆ, exponential gen hsa t Ï†âŸ«_â„‚) := by
    apply Filter.Tendsto.inner h_conv_Ïˆ h_conv_Ï†

  have h_const : Tendsto (fun n : â„•+ => âŸªÏˆ, Ï†âŸ«_â„‚) atTop (ğ“ âŸªÏˆ, Ï†âŸ«_â„‚) := tendsto_const_nhds

  have h_eq := tendsto_nhds_unique h_inner_cont (h_const.congr (fun n => (h_approx_unitary n).symm))
  exact h_eq

/-- **Exponential Satisfies Group Law**

The exponential satisfies the fundamental group property:

  exp(i(s+t)A)Ïˆ = exp(isA)(exp(itA)Ïˆ)

**Proof:**

Each approximant satisfies the group law (by `expBounded_group_law`):
  exp((s+t)Â·IÂ·Aâ‚™Ë¢Ê¸áµ) = exp(sÂ·IÂ·Aâ‚™Ë¢Ê¸áµ) âˆ˜ exp(tÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)

Passing to the limit requires care: we need exp(sÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)Ï‡ â†’ exp(isA)Ï‡
uniformly enough to compose with the inner convergence.

The key is using isometry: â€–exp(sÂ·IÂ·Aâ‚™Ë¢Ê¸áµ)â€– = 1 uniformly, allowing an
Îµ/2 argument to handle the composition.

**Physical significance:**

The group law says time evolution is composable: evolving for time s then
time t is the same as evolving for time s+t. This is the mathematical
statement of time-translation symmetry in quantum mechanics.
-/
theorem exponential_group_law
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (h_dense : Dense (gen.domain : Set H))
    (s t : â„) (Ïˆ : H) :
    exponential gen hsa (s + t) Ïˆ = exponential gen hsa s (exponential gen hsa t Ïˆ) := by
  have h_approx_group : âˆ€ n : â„•+,
      expBounded (I â€¢ yosidaApproxSym gen hsa n) (s + t) Ïˆ =
      expBounded (I â€¢ yosidaApproxSym gen hsa n) s (expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ) := by
    intro n
    rw [expBounded_group_law]
    exact rfl

  have h_conv_lhs : Tendsto (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) (s + t) Ïˆ)
                            atTop (ğ“ (exponential gen hsa (s + t) Ïˆ)) := by
    unfold exponential
    have h_eval : Continuous (fun T : H â†’L[â„‚] H => T Ïˆ) :=
      (ContinuousLinearMap.apply â„‚ H Ïˆ).continuous
    exact exponential_tendsto gen hsa h_dense (s + t) Ïˆ

  have h_conv_t : Tendsto (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ)
                          atTop (ğ“ (exponential gen hsa t Ïˆ)) := by
    unfold exponential
    have h_eval : Continuous (fun T : H â†’L[â„‚] H => T Ïˆ) :=
      (ContinuousLinearMap.apply â„‚ H Ïˆ).continuous
    exact exponential_tendsto gen hsa h_dense t Ïˆ

  have h_conv_rhs : Tendsto (fun n : â„•+ =>
      expBounded (I â€¢ yosidaApproxSym gen hsa n) s (expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ))
      atTop (ğ“ (exponential gen hsa s (exponential gen hsa t Ïˆ))) := by
    have h_inner := exponential_tendsto gen hsa h_dense t Ïˆ
    have h_outer : âˆ€ Ï‡ : H, Tendsto (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) s Ï‡)
                                    atTop (ğ“ (exponential gen hsa s Ï‡)) :=
      fun Ï‡ => exponential_tendsto gen hsa h_dense s Ï‡

    apply Metric.tendsto_atTop.mpr
    intro Îµ hÎµ
    have hÎµ2 : Îµ / 2 > 0 := by linarith

    rw [Metric.tendsto_atTop] at h_inner
    obtain âŸ¨Nâ‚, hNâ‚âŸ© := h_inner (Îµ / 2) hÎµ2

    have h_outer_limit := h_outer (exponential gen hsa t Ïˆ)
    rw [Metric.tendsto_atTop] at h_outer_limit
    obtain âŸ¨Nâ‚‚, hNâ‚‚âŸ© := h_outer_limit (Îµ / 2) hÎµ2

    use max Nâ‚ Nâ‚‚
    intro n hn
    rw [dist_eq_norm]

    calc â€–expBounded (I â€¢ yosidaApproxSym gen hsa n) s (expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ) -
          exponential gen hsa s (exponential gen hsa t Ïˆ)â€–
        = â€–(expBounded (I â€¢ yosidaApproxSym gen hsa n) s (expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ) -
           expBounded (I â€¢ yosidaApproxSym gen hsa n) s (exponential gen hsa t Ïˆ)) +
          (expBounded (I â€¢ yosidaApproxSym gen hsa n) s (exponential gen hsa t Ïˆ) -
           exponential gen hsa s (exponential gen hsa t Ïˆ))â€– := by congr 1; abel
      _ â‰¤ â€–expBounded (I â€¢ yosidaApproxSym gen hsa n) s (expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ) -
           expBounded (I â€¢ yosidaApproxSym gen hsa n) s (exponential gen hsa t Ïˆ)â€– +
          â€–expBounded (I â€¢ yosidaApproxSym gen hsa n) s (exponential gen hsa t Ïˆ) -
           exponential gen hsa s (exponential gen hsa t Ïˆ)â€– := norm_add_le _ _
      _ = â€–expBounded (I â€¢ yosidaApproxSym gen hsa n) s (expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ - exponential gen hsa t Ïˆ)â€– +
          â€–expBounded (I â€¢ yosidaApproxSym gen hsa n) s (exponential gen hsa t Ïˆ) -
           exponential gen hsa s (exponential gen hsa t Ïˆ)â€– := by rw [â† map_sub]
      _ = â€–expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ïˆ - exponential gen hsa t Ïˆâ€– +
          â€–expBounded (I â€¢ yosidaApproxSym gen hsa n) s (exponential gen hsa t Ïˆ) -
           exponential gen hsa s (exponential gen hsa t Ïˆ)â€– := by
            rw [expBounded_yosidaApproxSym_isometry gen hsa n s _]
      _ < Îµ / 2 + Îµ / 2 := by
            apply add_lt_add
            Â· rw [â† dist_eq_norm]; exact hNâ‚ n (le_of_max_le_left hn)
            Â· rw [â† dist_eq_norm]; exact hNâ‚‚ n (le_of_max_le_right hn)
      _ = Îµ := by ring

  have h_eq := tendsto_nhds_unique h_conv_lhs (h_conv_rhs.congr (fun n => (h_approx_group n).symm))
  exact h_eq

/-- **Exponential at Zero is Identity**

exp(iÂ·0Â·A)Ïˆ = Ïˆ

**Proof:**

Each approximant at t=0 is the identity (by `expBounded_at_zero`):
  exp(0Â·IÂ·Aâ‚™Ë¢Ê¸áµ)Ïˆ = Ïˆ

The constant sequence Ïˆ converges to Ïˆ, which must equal exponential(0)Ïˆ.

**Role in group structure:**

This is one of the group axioms: U(0) must be the identity. Combined with
the group law, it implies U(t)U(-t) = U(0) = I, so U(-t) = U(t)â»Â¹.
-/
theorem exponential_identity
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (h_dense : Dense (gen.domain : Set H))
    (Ïˆ : H) :
    exponential gen hsa 0 Ïˆ = Ïˆ := by
  have h_approx_zero : âˆ€ n : â„•+, expBounded (I â€¢ yosidaApproxSym gen hsa n) 0 Ïˆ = Ïˆ :=
    fun n => expBounded_at_zero _ Ïˆ

  have h_const : Tendsto (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) 0 Ïˆ)
                         atTop (ğ“ Ïˆ) := by
    simp_rw [h_approx_zero]
    exact tendsto_const_nhds

  have h_conv : Tendsto (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) 0 Ïˆ)
                        atTop (ğ“ (exponential gen hsa 0 Ïˆ)) := by
    unfold exponential
    have h_eval : Continuous (fun T : H â†’L[â„‚] H => T Ïˆ) :=
      (ContinuousLinearMap.apply â„‚ H Ïˆ).continuous
    exact exponential_tendsto gen hsa h_dense 0 Ïˆ

  exact tendsto_nhds_unique h_conv h_const

/-- **Exponential is Strongly Continuous**

For each Ïˆ âˆˆ H, the map t â†¦ exp(itA)Ïˆ is continuous.

**Proof:**

On domain elements Ï† âˆˆ D(A), the exponential equals the original unitary group U(t)Ï†
(by convergence to the limit). Since U is strongly continuous, so is exponential on D(A).

For general Ïˆ âˆˆ H, use an Îµ/3 argument:
  1. Approximate Ïˆ by Ï† âˆˆ D(A)
  2. Use continuity at Ï†
  3. Control errors using isometry â€–exp(itA)(Ïˆ - Ï†)â€– = â€–Ïˆ - Ï†â€–

**Physical significance:**

Strong continuity means small changes in time produce small changes in the
evolved state. This is essential for the physical interpretation: time
evolution should not have discontinuous jumps.

**Definition of Câ‚€-group:**

A one-parameter group is called a Câ‚€-group (or strongly continuous group) if
it satisfies this continuity condition. Stone's theorem characterizes precisely
which operators generate Câ‚€-unitary groups: the self-adjoint operators.
-/
theorem exponential_strong_continuous
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (h_dense : Dense (gen.domain : Set H))
    (Ïˆ : H) :
    Continuous (fun t : â„ => exponential gen hsa t Ïˆ) := by
  have h_exp_eq_U : âˆ€ (Ï† : H), Ï† âˆˆ gen.domain â†’ âˆ€ t : â„, exponential gen hsa t Ï† = U_grp.U t Ï† := by
    intro Ï† hÏ† t
    have h_tendsto := expBounded_yosidaApproxSym_tendsto_unitary gen hsa h_dense t Ï† hÏ†
    have h_conv : Tendsto (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†)
                          atTop (ğ“ (exponential gen hsa t Ï†)) := by

      unfold exponential
      have h_eval : Continuous (fun T : H â†’L[â„‚] H => T Ï†) :=
        (ContinuousLinearMap.apply â„‚ H Ï†).continuous
      exact exponential_tendsto gen hsa h_dense t Ï†
    exact tendsto_nhds_unique h_conv h_tendsto

  have h_cont_domain : âˆ€ (Ï† : H), Ï† âˆˆ gen.domain â†’
      Continuous (fun t : â„ => exponential gen hsa t Ï†) := by
    intro Ï† hÏ†
    have h_eq : (fun t => exponential gen hsa t Ï†) = (fun t => U_grp.U t Ï†) := by
      ext t
      exact h_exp_eq_U Ï† hÏ† t
    rw [h_eq]
    exact U_grp.strong_continuous Ï†

  have h_isometry : âˆ€ t : â„, âˆ€ (Ï‡ : H), â€–exponential gen hsa t Ï‡â€– = â€–Ï‡â€– := by
    intro t Ï‡
    have h_inner := exponential_unitary gen hsa h_dense t Ï‡ Ï‡
    rw [inner_self_eq_norm_sq_to_K, inner_self_eq_norm_sq_to_K] at h_inner
    have h_sq : â€–exponential gen hsa t Ï‡â€–^2 = â€–Ï‡â€–^2 := by
      have h_eq : (â€–exponential gen hsa t Ï‡â€– : â„‚)^2 = (â€–Ï‡â€– : â„‚)^2 := by
        exact h_inner
      exact_mod_cast h_eq
    rw [â† Real.sqrt_sq (norm_nonneg (exponential gen hsa t Ï‡)),
        â† Real.sqrt_sq (norm_nonneg Ï‡), h_sq]

  rw [Metric.continuous_iff]
  intro t Îµ hÎµ

  have hÎµ3 : Îµ / 3 > 0 := by linarith

  obtain âŸ¨Ï†, hÏ†_mem, hÏ†_closeâŸ© := Metric.mem_closure_iff.mp
    (h_dense.closure_eq â–¸ Set.mem_univ Ïˆ) (Îµ / 3) hÎµ3
  rw [dist_eq_norm] at hÏ†_close

  have h_cont_Ï† := h_cont_domain Ï† hÏ†_mem
  rw [Metric.continuous_iff] at h_cont_Ï†
  obtain âŸ¨Î´, hÎ´_pos, hÎ´âŸ© := h_cont_Ï† t (Îµ / 3) hÎµ3

  use Î´, hÎ´_pos
  intro s hs
  rw [dist_eq_norm]

  calc â€–exponential gen hsa s Ïˆ - exponential gen hsa t Ïˆâ€–
      = â€–(exponential gen hsa s Ïˆ - exponential gen hsa s Ï†) +
         (exponential gen hsa s Ï† - exponential gen hsa t Ï†) +
         (exponential gen hsa t Ï† - exponential gen hsa t Ïˆ)â€– := by abel_nf
    _ â‰¤ â€–exponential gen hsa s Ïˆ - exponential gen hsa s Ï†â€– +
        â€–exponential gen hsa s Ï† - exponential gen hsa t Ï†â€– +
        â€–exponential gen hsa t Ï† - exponential gen hsa t Ïˆâ€– := by
          apply le_trans (norm_add_le _ _)
          apply add_le_add_right
          exact norm_add_le _ _
    _ = â€–exponential gen hsa s (Ïˆ - Ï†)â€– +
        â€–exponential gen hsa s Ï† - exponential gen hsa t Ï†â€– +
        â€–exponential gen hsa t (Ï† - Ïˆ)â€– := by
          rw [â† map_sub (exponential gen hsa s), â† map_sub (exponential gen hsa t)]
    _ = â€–Ïˆ - Ï†â€– + â€–exponential gen hsa s Ï† - exponential gen hsa t Ï†â€– + â€–Ï† - Ïˆâ€– := by
          rw [h_isometry s (Ïˆ - Ï†), h_isometry t (Ï† - Ïˆ)]
    _ < Îµ / 3 + Îµ / 3 + Îµ / 3 := by
          apply add_lt_add
          apply add_lt_add
          Â· exact hÏ†_close
          Â· rw [â† dist_eq_norm]; exact hÎ´ s hs
          Â· rw [norm_sub_rev]; exact hÏ†_close
    _ = Îµ := by ring

/-- **Generator of the Exponential is A**

The generator of the unitary group t â†¦ exp(itA) is A itself:

  lim_{tâ†’0} (exp(itA)Ï† - Ï†)/(it) = AÏ†  for Ï† âˆˆ D(A)

Equivalently: lim_{tâ†’0} tâ»Â¹(exp(itA)Ï† - Ï†) = iAÏ†

**Proof:**

On domain elements, exponential(t)Ï† = U(t)Ï† (the original unitary group).
The generator formula for U gives:
  lim_{tâ†’0} (IÂ·t)â»Â¹(U(t)Ï† - Ï†) = AÏ†

Converting: tâ»Â¹ = IÂ·(IÂ·t)â»Â¹, so tâ»Â¹(U(t)Ï† - Ï†) = IÂ·((IÂ·t)â»Â¹(U(t)Ï† - Ï†)) â†’ IÂ·AÏ†

**Completing Stone's theorem:**

This result shows the correspondence A â†¦ exp(itA) â†¦ (generator of exp(itA)) = A
is the identity. Combined with the other direction (any Câ‚€-unitary group has
a self-adjoint generator), this establishes the bijection of Stone's theorem.
-/
theorem exponential_generator_eq
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (h_dense : Dense (gen.domain : Set H))
    (Ï† : H) (hÏ† : Ï† âˆˆ gen.domain) :
    Tendsto (fun t : â„ => (tâ»Â¹ : â„‚) â€¢ (exponential gen hsa t Ï† - Ï†))
            (ğ“[â‰ ] 0) (ğ“ (I â€¢ gen.op Ï†)) := by
  have h_exp_eq_U : âˆ€ t : â„, exponential gen hsa t Ï† = U_grp.U t Ï† := by
    intro t
    have h_tendsto := expBounded_yosidaApproxSym_tendsto_unitary gen hsa h_dense t Ï† hÏ†
    have h_conv : Tendsto (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) t Ï†)
                          atTop (ğ“ (exponential gen hsa t Ï†)) := by
      unfold exponential
      have h_eval : Continuous (fun T : H â†’L[â„‚] H => T Ï†) :=
        (ContinuousLinearMap.apply â„‚ H Ï†).continuous
      exact exponential_tendsto gen hsa h_dense t Ï†
    exact tendsto_nhds_unique h_conv h_tendsto

  have h_eq_seq : âˆ€ t : â„, (tâ»Â¹ : â„‚) â€¢ (exponential gen hsa t Ï† - Ï†) =
                          (tâ»Â¹ : â„‚) â€¢ (U_grp.U t Ï† - Ï†) := by
    intro t
    rw [h_exp_eq_U t]

  have h_gen_formula := gen.generator_formula Ï† hÏ†

  have h_scalar : âˆ€ t : â„, t â‰  0 â†’ (tâ»Â¹ : â„‚) = I * (I * (t : â„‚))â»Â¹ := by
    intro t ht
    field_simp

  have h_transform : âˆ€ t : â„, t â‰  0 â†’
      (tâ»Â¹ : â„‚) â€¢ (U_grp.U t Ï† - Ï†) = I â€¢ ((I * (t : â„‚))â»Â¹ â€¢ (U_grp.U t Ï† - Ï†)) := by
    intro t ht
    rw [â† smul_assoc, h_scalar t ht]
    exact rfl

  refine Tendsto.congr' ?_ (Filter.Tendsto.const_smul h_gen_formula I)
  filter_upwards [self_mem_nhdsWithin] with t ht
  rw [h_eq_seq t, h_transform t ht]



/-- **Derivative of Exponential on Domain**

For Ï† âˆˆ D(A), the exponential is differentiable with derivative iAÂ·exp(itA)Ï†:

  d/dt[exp(itA)Ï†] = iAÂ·exp(itA)Ï†

**Proof:**

Using the group law and generator formula:
  d/dt[exp(itA)Ï†] = lim_{hâ†’0} (exp(i(t+h)A)Ï† - exp(itA)Ï†)/h
                  = lim_{hâ†’0} (exp(itA)(exp(ihA)Ï† - Ï†))/h
                  = exp(itA) Â· lim_{hâ†’0} (exp(ihA)Ï† - Ï†)/h
                  = exp(itA) Â· (iAÏ†)
                  = iAÂ·exp(itA)Ï†

The last equality uses commutativity AÂ·U(t) = U(t)Â·A on domain elements.

**This is the SchrÃ¶dinger equation:**

Writing Ïˆ(t) = exp(itA)Ï†, the derivative formula becomes:
  dÏˆ/dt = iAÏˆ

which is the time-dependent SchrÃ¶dinger equation with Hamiltonian A (in units
where â„ = 1). Stone's theorem thus provides the mathematical foundation for
quantum dynamics.
-/
theorem exponential_derivative_on_domain
    {U_grp : OneParameterUnitaryGroup (H := H)}
    (gen : Generator U_grp) (hsa : gen.IsSelfAdjoint)
    (h_dense : Dense (gen.domain : Set H))
    (t : â„) (Ïˆ : H) (hÏˆ : Ïˆ âˆˆ gen.domain) :
    HasDerivAt (fun s : â„ => exponential gen hsa s Ïˆ)
               (I â€¢ gen.op (exponential gen hsa t Ïˆ))
               t := by
  have h_exp_eq_U : âˆ€ s : â„, exponential gen hsa s Ïˆ = U_grp.U s Ïˆ := by
    intro s
    have h_tendsto := expBounded_yosidaApproxSym_tendsto_unitary gen hsa h_dense s Ïˆ hÏˆ
    have h_conv : Tendsto (fun n : â„•+ => expBounded (I â€¢ yosidaApproxSym gen hsa n) s Ïˆ)
                          atTop (ğ“ (exponential gen hsa s Ïˆ)) := by
      unfold exponential
      have h_eval : Continuous (fun T : H â†’L[â„‚] H => T Ïˆ) :=
        (ContinuousLinearMap.apply â„‚ H Ïˆ).continuous
      exact exponential_tendsto gen hsa h_dense s Ïˆ

    exact tendsto_nhds_unique h_conv h_tendsto

  have h_fun_eq : (fun s : â„ => exponential gen hsa s Ïˆ) = (fun s : â„ => U_grp.U s Ïˆ) := by
    ext s
    exact h_exp_eq_U s

  rw [h_fun_eq]

  have hUtÏˆ : U_grp.U t Ïˆ âˆˆ gen.domain := gen.domain_invariant t Ïˆ hÏˆ

  rw [hasDerivAt_iff_tendsto_slope]

  have h_diff : âˆ€ s : â„, U_grp.U s Ïˆ - U_grp.U t Ïˆ = U_grp.U t (U_grp.U (s - t) Ïˆ - Ïˆ) := by
    intro s
    have h1 : U_grp.U s Ïˆ = U_grp.U (t + (s - t)) Ïˆ := by ring_nf
    have h2 : U_grp.U (t + (s - t)) Ïˆ = U_grp.U t (U_grp.U (s - t) Ïˆ) := by
      rw [U_grp.group_law]; rfl
    calc U_grp.U s Ïˆ - U_grp.U t Ïˆ
        = U_grp.U t (U_grp.U (s - t) Ïˆ) - U_grp.U t Ïˆ := by rw [h1, h2]
      _ = U_grp.U t (U_grp.U (s - t) Ïˆ - Ïˆ) := by rw [ContinuousLinearMap.map_sub]

  have h_slope : âˆ€ s : â„, s â‰  t â†’ slope (fun s => U_grp.U s Ïˆ) t s =
      U_grp.U t ((s - t)â»Â¹ â€¢ (U_grp.U (s - t) Ïˆ - Ïˆ)) := by
    intro s hs
    simp only [slope, vsub_eq_sub, h_diff s]
    exact
      Eq.symm
        (ContinuousLinearMap.map_smul_of_tower (U_grp.U t) (s - t)â»Â¹ ((U_grp.U (s - t)) Ïˆ - Ïˆ))


  have h_gen := gen.generator_formula Ïˆ hÏˆ

  have h_convert : âˆ€ h : â„, h â‰  0 â†’ (hâ»Â¹ : â„‚) â€¢ (U_grp.U h Ïˆ - Ïˆ) =
      I â€¢ ((I * (h : â„‚))â»Â¹ â€¢ (U_grp.U h Ïˆ - Ïˆ)) := by
    intro h hh
    rw [â† smul_assoc]
    congr 1
    rw [smul_eq_mul, mul_inv_rev, Complex.inv_I, mul_neg, mul_comm ((â†‘h)â»Â¹) I,
        â† neg_mul, â† mul_assoc]
    simp

  have h_lim : Tendsto (fun s : â„ => ((s - t)â»Â¹ : â„‚) â€¢ (U_grp.U (s - t) Ïˆ - Ïˆ))
                       (ğ“[â‰ ] t) (ğ“ (I â€¢ gen.op Ïˆ)) := by
    have h_comp : Tendsto (fun s : â„ => s - t) (ğ“[â‰ ] t) (ğ“[â‰ ] 0) := by
      apply tendsto_nhdsWithin_of_tendsto_nhds_of_eventually_within
      Â· have h : Tendsto (fun s : â„ => s - t) (ğ“ t) (ğ“ (t - t)) :=
          tendsto_id.sub tendsto_const_nhds
        simp only [sub_self] at h
        exact h.mono_left nhdsWithin_le_nhds
      Â· filter_upwards [self_mem_nhdsWithin] with s hs
        simp only [Set.mem_compl_iff, Set.mem_singleton_iff, sub_eq_zero]
        exact hs
    have h_inner := h_gen.comp h_comp
    have h_smul := h_inner.const_smul I
    refine h_smul.congr' ?_
    filter_upwards [self_mem_nhdsWithin] with s hs
    rw [â† ofReal_sub]
    exact (h_convert (s - t) (sub_ne_zero.mpr hs)).symm

  have h_final : Tendsto (slope (fun s => U_grp.U s Ïˆ) t) (ğ“[â‰ ] t) (ğ“ (I â€¢ gen.op (U_grp.U t Ïˆ))) := by
    have h_Ut_cont : Continuous (U_grp.U t) := (U_grp.U t).continuous
    have h_composed := h_Ut_cont.continuousAt.tendsto.comp h_lim
    have h_comm : U_grp.U t (I â€¢ gen.op Ïˆ) = I â€¢ gen.op (U_grp.U t Ïˆ) := by
      rw [ContinuousLinearMap.map_smul, generator_commutes_unitary gen t Ïˆ hÏˆ]
    rw [h_comm] at h_composed
    refine h_composed.congr' ?_
    filter_upwards [self_mem_nhdsWithin] with s hs
    simp only [Function.comp_apply]
    convert (h_slope s hs).symm using 2
    rw [â† Complex.ofReal_sub]
    rw [â† h_exp_eq_U]
    norm_cast

  rw [h_exp_eq_U, â† h_exp_eq_U, h_exp_eq_U]
  exact h_final

/-
## Summary
This completes the documentation for the Yosida approximation file. Here's the overall structure:
Section 0: Arithmetic lemmas for complex spectral parameters (IÂ·n, -IÂ·n)
Section 1: Core Yosida operator definitions (Aâ‚™, Aâ‚™Ë¢Ê¸áµ, Jâ‚™, Jâ‚™â»)
Section 2: Norm bounds (â€–Aâ‚™â€– â‰¤ 2n, â€–Jâ‚™â€– â‰¤ 1)
Section 3: Self-adjointness of Aâ‚™Ë¢Ê¸áµ and skew-adjointness of IÂ·Aâ‚™Ë¢Ê¸áµ
Section 4: J operator identities and convergence (Jâ‚™ â†’ I strongly)
Section 5: Yosida approximant convergence (Aâ‚™Ï† â†’ AÏ† on domain)
Section 6: Exponential of bounded operators (definition, group law, adjoint, unitarity)
Section 7: Unitarity of Yosida exponentials (inner product and norm preservation)
Section 8: Cauchy sequences and exponential definition (Duhamel estimate, convergence)
- Epanded with Bochner and Uniform Convergence for Duhamel
Section 9: Properties of exp(itA) (unitarity, group law, strong continuity, generator = A)
Axiomatized results (marked with sorry):

duhamel_estimate: Requires Bochner integration
yosidaApproxSym_uniform_convergence_on_orbit: Requires compactness/Dini's theorem machinery
exponential_tendsto: Relates operator limit to pointwise limit

These axiomatizations isolate the analytic/measure-theoretic content from the algebraic structure,
following the same philosophy as VonNeumann.lean.
-/

end StonesTheorem.Exponential
